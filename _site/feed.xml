<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-26T14:15:12+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Bills.Data</title><subtitle>Exploring ideas in data science</subtitle><author><name>Bill Oxbury</name></author><entry><title type="html">What are geometric neural networks?</title><link href="http://localhost:4000/data_science/mathematics/clifford-nn-notes/" rel="alternate" type="text/html" title="What are geometric neural networks?" /><published>2024-01-23T00:00:00+00:00</published><updated>2024-01-23T00:00:00+00:00</updated><id>http://localhost:4000/data_science/mathematics/clifford-nn-notes</id><content type="html" xml:base="http://localhost:4000/data_science/mathematics/clifford-nn-notes/">&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-23/multivector.png&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;
  Clifford group equivariance for ${\mathbb R}^3$. From [5].
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is intended as working notes to get my head round some of the literature on geometric deep learning and Clifford algebra neural networks (NNs).&lt;/p&gt;

&lt;p&gt;&lt;small&gt;
&lt;b&gt;Contents:&lt;/b&gt;
&lt;ol&gt;
  &lt;li&gt;Notation for NN layers&lt;/li&gt;
  &lt;li&gt;Convolutional NNs&lt;/li&gt;
  &lt;li&gt;Group-equivariant CNNs&lt;/li&gt;
  &lt;li&gt;Example: spherical CNNs&lt;/li&gt;
  &lt;li&gt;How convolutional kernels are learned from data&lt;/li&gt;
  &lt;li&gt;Enter Clifford algebras&lt;/li&gt;
  &lt;li&gt;A short zoo of applications&lt;/li&gt;
&lt;/ol&gt;
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Notation for NN layers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Recall that a NN layer is a function ${\bf x} \in {\mathbb R}^n \rightarrow {\bf y} \in {\mathbb R}^m$ of the form
${\bf \sigma} \circ W$ where $W$ is a $m \times n$ matrix and ${\bf \sigma} = (\sigma, \ldots , \sigma)$ is componentwise application of a nonlinear function $\sigma: {\mathbb R} \to {\mathbb R}$ (which maybe sigmoidal, or piecewise linear, or a step function, or something else).&lt;/p&gt;

&lt;p&gt;A neural network is simply a composition of such layers.&lt;/p&gt;

&lt;p&gt;Let $I$ be the index set {$1, \ldots , n $} for the units on the left (the components of ${\bf x}$) and $J$ the index set {$ 1, \ldots , m$} for the units on the right.
It will be helpful to treat ${\bf x} , {\bf y}$ as functions $I \to {\mathbb R}$, $J \to {\mathbb R}$ respectively. 
To emphasise this, I’ll write ${\bf x}  \in  {\mathbb R}^I$ and ${\bf y}  \in  {\mathbb R}^J$.&lt;/p&gt;

&lt;p&gt;We’ll first generalise $I,J$ to sets with more structure; then eventually we’ll generalise ${\mathbb R}$ to a bigger algebra.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Convolutional NNs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the 2010s, the use of NNs for image processing was revolutionised by the introduction of &lt;em&gt;convolutional NNs&lt;/em&gt; (CNNs). (See [1].)&lt;/p&gt;

&lt;p&gt;In a CNN, we first take $I,J \subset {\mathbb Z}^2$. That is, NN units represent pixels in a 2D array. WLOG we can treat $I,J$ as &lt;em&gt;equal to&lt;/em&gt; ${\mathbb Z}^2$ (but then constrain the support of the functions ${\bf x} , {\bf y}$).
More precisely, we think of each of $I,J$ as the &lt;em&gt;set&lt;/em&gt; ${\mathbb Z}^2$, acted on by the &lt;em&gt;group&lt;/em&gt; ${\mathbb Z}^2$.&lt;/p&gt;

&lt;p&gt;All or some of the layers of a CNN then have the form of a convolution: that is, the function $W{\bf x}: J \to {\mathbb R}$ is a convolution $K \star {\bf x}$ for some function (with finite support) $K: {\mathbb Z}^2 \to {\mathbb R}$.&lt;/p&gt;

&lt;p&gt;In other words, the kernel $K$ is a filter which slides around the 2D pixel array $I$. Here’s a picture where $K$ has $2\times 2$ support:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-23/cnn-filter.jpg&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;For a given pixel $i \in I$ and filter position $j \in J$, the linear coefficient $W_{ij}$ in the NN layer is simply the entry in $K$ over $i$ when the filter is at position $j$. (Exercise: write down a formula!)&lt;/p&gt;

&lt;p&gt;What are the benefits of a convolutional layer?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It’s efficient in model size: the matrix $W$ has $O(n)$ degrees of freedom 
instead of $O(n^2)$ (where $n = |I|$).&lt;/li&gt;
  &lt;li&gt;It regularises across the image - reducing the likelihood of overfitting to treat the left-hand side of the image differently from the right-hand side, say.&lt;/li&gt;
  &lt;li&gt;It is &lt;em&gt;translation-equivariant&lt;/em&gt;. That is, as a function, the layer commutes with translation by ${\mathbb Z}^2$. If the image is shifted north-east a bit, the model won’t notice.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Group-equivariant CNNs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;CNNs have a useful generalisation, first introduced in [2] (and probably elsewhere around that time). 
Suppose that a group $G$ acts on both $I,J$. For simplicity I’ll assume these actions are transitive - otherwise the arguments below are applied orbit-wise.&lt;/p&gt;

&lt;p&gt;So we are generalising the case $G = {\mathbb Z}^2$ above. Just as in that case, we get induced actions on the functions ${\bf x}, {\bf y}$ by ${\bf x}^g (i) = {\bf x} (i^{g^{-1}})$ and similar for ${\bf y}$. We seek equivariance, meaning that these actions commute with $W$:
\[
W {\bf x}^g = (W {\bf x})^g
\qquad
\hbox{for all $g \in G$.}
\]
In [2] it is shown that $W$ is equivariant in this sense if and only if it is convolutional:
\[
W {\bf x}  = K \star {\bf x} \in {\mathbb R}^J
\qquad
\hbox{for some $K \in {\mathbb R}^G$.}
\]
To be precise: fix some origins $i_0 \in I$ and $j_0 \in J$. Under the assumption of transitivity, any $i,j$ can be represented as $i = i_0^{g_i}$, $j = j_0^{g_j}$ for some $g_i, g_j \in G$. Then the convolution statement is equivalent to 
\[
W_{ij}  = K(g_i^{-1} g_j).
\]&lt;/p&gt;

&lt;p&gt;Why does equivariance matter? If, as in the 2D image case, it is a natural requirement in the scenario we’re modelling, then it makes sense to build it into the mathemtical structure of the model. The alternative is that it is learned - imperfectly - from training data. Having equivariance (or &lt;em&gt;invariance&lt;/em&gt; of the final output such as a classification of the image) built in directly represents an important saving in the data requirements for training.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Example: spherical CNNs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here’s an example from [3]. Various 3D imaging applications need to model pixels on the 2-sphere - for example, from drone or satellite imagery.&lt;/p&gt;

&lt;p&gt;In this case $I,J \subset S^2$ and $G$ is the 3D rotation group $SO(3)$. The matrix $W$ is a linear transformation of ${\bf x}: I = S^2 \to {\mathbb R}$ and is modelled as a convolution with a kernel $K : SO(3) \to {\mathbb R}$.&lt;/p&gt;

&lt;p&gt;The group $SO(3)$ is 3-dimensional, with a coordinate chart given by &lt;a href=&quot;https://en.wikipedia.org/wiki/Euler_angles&quot; target=&quot;_blank&quot;&gt;Euler angles&lt;/a&gt; $\alpha,\beta,\gamma$. A kernel $K$ is specified to have bounded support in some window of $(\alpha,\beta,\gamma)$-space. The convolution is then expressed as an integral
\[
(K \star {\bf x}) (R) = \int_{SO(3)} K(R^{-1} Q) {\bf x}(Q) dQ,
\]
whose computation requires some &lt;a href=&quot;https://en.wikipedia.org/wiki/Wigner_D-matrix&quot; target=&quot;_blank&quot;&gt;representation theory of $SO(3).$&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Clifford algebras will offer a cleaner way to encode $SO(n)$ and $O(n)$-equivariance - and also with more tractable generalisation to $n &amp;gt; 3$.&lt;/p&gt;

&lt;p&gt;Before coming to that, though, let’s remind ourselves that a NN model is to be learned from training data - how that is done, and how to incorporate convolutional layers in that process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. How convolutional kernels are learned from data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A neural network is a composite function $f: {\bf x} \to \cdots \to {\bf y}$ which seeks to model the conditional distribution $P(Y \mid X)$ for random variables $X,Y$. For example, $X$ may represent 2D pixel arrays and $Y$ the binary variable ‘image contains a cat’.&lt;/p&gt;

&lt;p&gt;A training data set $D$ for $f$ consists of pairs $(x,y)$ drawn from the joint distribution of $X$ and $Y$. For each such pair we can evaluate $\hat{y} = f(x)$ and measure the distance $d(\hat{y}, y)$ (for a suitable metric $d$).&lt;/p&gt;

&lt;p&gt;We can define an error function (usually called the &lt;em&gt;loss function&lt;/em&gt;)
\[
E_D(f) = \sum_{(x,y) \in D} d(\hat{y}, y).
\]
Training the model now means choosing the parameters of $f$ to minimise $E_D(f)$.&lt;/p&gt;

&lt;p&gt;This minimisation takes place over linear coefficients in the $W$-matrices and kernels $K$ in the layers of the network. We assume the ‘architecture’ is fixed - that is, the number and size of layers, and the filter structure in the convolutional kernels.&lt;/p&gt;

&lt;p&gt;We can assume WLOG that all layers are convolutional.
That means we can treat the error as a function of the linear $K$ coefficients in all the layers, $E_D(K)$. This is a function over a big vector space, we need to compute the derivative $\nabla_K(E_D)$.&lt;/p&gt;

&lt;p&gt;Computing this derivative uses the chain rule. Let’s recall how this works.&lt;/p&gt;

&lt;p&gt;Suppose, as an example, we want to differentiate the function
\[
F(u,v) = u + v\sin(u+v).
\]
Here’s a picture of what we do:&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-23/chainrule.png&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;
  From an old PowerPoint c2014. Not sure what I was on.
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I’ve decomposed $F$ into a directed acyclic graph (DAG) of simple compononents. Evaluating the function involves a forward pass through this DAG.&lt;/p&gt;

&lt;p&gt;The reverse (red) arrows are the computed derivatives of each arrow on its own. The chain rule for the end-to-end derivative can be written as:
\[
\frac{\partial F}{\partial u} = \sum_{\hbox{paths $u \leftarrow F$}} \prod (\hbox{edges along the path}).
\]
(Exercise: check this for the example!)&lt;/p&gt;

&lt;p&gt;The beauty of this formulation is that &lt;em&gt;we don’t need to enumerate all the paths&lt;/em&gt;: we only need to pass messages back along the red edges, multiplying as we go and summing the incoming messages. The messages that then arrive at the variables $u,v$ will then be the respective partial derivatives.&lt;/p&gt;

&lt;p&gt;This formulation of the chain rule is called &lt;em&gt;back-propagation&lt;/em&gt;. Let’s see how it works for the derivative $\nabla_K(E_D)$.&lt;/p&gt;

&lt;p&gt;The DAG for the function $E_D(K)$ decomposes in the following way:
\[
\hbox{$K$ coeffs} \rightarrow \hbox{$W$ coeffs} \rightarrow \hbox{NN units} \rightarrow E_D.&lt;br /&gt;
\]
(Plus arrows among the NN units corresponding to network connections, not drawn.)&lt;/p&gt;

&lt;p&gt;Back-propagation has only a simple derivative to compute along each edge in this graph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. Enter Clifford algebras&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To motivate what comes next, let’s briefly compare two problems.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Problem 1: colour image classification.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Our input images now have three colour (RGB) channels, so we imagine a model with input
\[
{\bf x} : I = {\mathbb Z}^2 \rightarrow {\mathbb R} \oplus {\mathbb R} \oplus{\mathbb R}.
\]
For this, an initial NN layer will be constructed by learning an independent kernel on each channel and summing the convolutions:&lt;/p&gt;
&lt;p&gt;$$
K_{\rm red} \star {\bf x}_1 + K_{\rm blue} \star {\bf x}_2 + K_{\rm green} \star {\bf x}_3.
$$
&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Problem 2: shallow water flow.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Here, the task is to predict fluid flow in the plane - that is to model velocity and pressure fields a few time steps in the future, given those fields now. So at each time step, input to the model looks like
\[
{\bf x} : I = {\mathbb Z}^2 \rightarrow {\mathbb R} \oplus {\mathbb R}^2
\]&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-23/fluidflow.png&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;
  A problem with 3 scalar fields over the plane (columns), with the aim of predicting future evolution (rows). Clearly the fields are far from independent. From [7].
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The standard approach would be to treat Problem 2 in the same way as Problem 1. However, this fails to exploit the geometric structure of the problem: two of the columns should be encoded not as independent scalars but as a single vector.&lt;/p&gt;

&lt;p&gt;Mathematically, what this means is that we’d like to build in not just ${\mathbb Z}^2$-equivariance with respect to $I,J$, but $O(2)$-equivariance with respect to ${\mathbb R} \oplus {\mathbb R}^2$ (where $O(2)$ acts trivially on the first factor and as rotations/reflections on the second).&lt;/p&gt;

&lt;p&gt;This can be achieved by treating ${\mathbb R} \oplus {\mathbb R}^2$ as contained in one of the Clifford algebras $Cl_{2,0}$ or $Cl_{0,2}$ (we can choose either). I’ll spell this out in just a moment, but the key thing to note is that as soon as 
\[
{\bf x} : I \rightarrow A
\quad
\hbox{and}
\quad
K : {\mathbb Z}^2 \rightarrow A
\]
(where $A$ is one of the two Clifford algebras) then convolution works exactly as before - all the formulae work fine over $A$ because we can add and multiply elements just as for ${\mathbb R}$.&lt;/p&gt;

&lt;p&gt;OK, so let’s spell this out. In both cases, $A$ has a basis $1, e_1, e_2, e_3 := e_1e_2$ where $e_1, e_2$ is a basis for the Euclidean ${\mathbb R}^2$ we’re interested in. By definition,
\[
x^2 := \pm (x \cdot x) 1
\qquad
\hbox{for $x \in {\mathbb R}^2 \subset A$.}
\]
The sign determines which of the two cases we’re in.&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Case $A = Cl_{2,0}$ &lt;/b&gt; (called ‘Clifford Fourier’ in [7])&lt;/p&gt;

&lt;p&gt;In this case $e_1^2 = e_2^2 = 1$ and it’s easy to check that $e_1 e_2 = - e_2 e_1$ and $e_3^2 = -1$.
So we can write down an (algebra) isomorphism to real $2 \times 2$ matrices $Cl_{2,0} \cong {\mathbb R}(2)$&lt;/p&gt;

&lt;p&gt;$$
1 \mapsto
  \begin{pmatrix} 
  1 &amp;amp; 0 \\
0 &amp;amp; 1  \end{pmatrix},
\quad
e_1 \mapsto
  \begin{pmatrix} 
  0 &amp;amp; 1 \\
-1 &amp;amp; 0 \end{pmatrix},
$$$$
e_2 \mapsto
  \begin{pmatrix} 
  1 &amp;amp; 0 \\
0 &amp;amp; -1  \end{pmatrix},
\quad
e_3 \mapsto
  \begin{pmatrix} 
  0 &amp;amp; 1 \\
1 &amp;amp; 0  \end{pmatrix}.
$$&lt;/p&gt;
&lt;p&gt;Exercise: show that for any ${ x}, { y} \in {\mathbb R}^2$, their product in&lt;br /&gt;
$Cl_{2,0}$ is
\[
{x}  {y} = ({ x}\cdot { y}, 0,0, \det |{ x}\, { y}|) \in  {\mathbb R}^4 \cong Cl_{2,0}.
\]&lt;/p&gt;

&lt;p&gt;&lt;b&gt; Case $A = Cl_{0,2}$ &lt;/b&gt; (called ‘rotational Clifford’ in [7])&lt;/p&gt;

&lt;p&gt;In this case $e_1^2 = e_2^2 = -1$ but as in the previous case $e_1 e_2 = - e_2 e_1$ and $e_3^2 = -1$.
So this time the algebra is isomorphic to the quarternions $Cl_{2,0} \cong {\mathbb H}$. If we want to we can represent the algebra as $2 \times 2$ complex matrices ${\mathbb H} \subset {\mathbb C}(2)$. Then the basis elements map to the &lt;em&gt;Pauli matrices&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;$$
1 \mapsto
  \begin{pmatrix} 
  1 &amp;amp; 0 \\
0 &amp;amp; 1  \end{pmatrix},
\quad
e_1 \mapsto
  \begin{pmatrix} 
  0 &amp;amp; i \\
i &amp;amp; 0 \end{pmatrix},
$$$$
e_2 \mapsto
  \begin{pmatrix} 
  0 &amp;amp; 1 \\
-1 &amp;amp; 0  \end{pmatrix},
\quad
e_3 \mapsto
  \begin{pmatrix} 
  -i &amp;amp; 0 \\
0 &amp;amp; i  \end{pmatrix}
$$&lt;/p&gt;
&lt;p&gt;where $i = \sqrt{-1}$.&lt;/p&gt;

&lt;p&gt;Whether we choose to learn rotational of Fourier Clifford kernels is a design choice, as are other aspects of the NN architecture. For either choice, the kernels are learnt (by back-propagation) and deployed in exactly the same way as for layers defined purely over ${\mathbb R}$ - but now the $O(2)$-geometric structure is built in.&lt;/p&gt;

&lt;p&gt;For 3D problems, where we want a model to respect $O(3)$ geometry, the story is similar. The Clifford algebra (for choice of signature, or choice of sign on the Euclidean inner product) is 8-dimensional over ${\mathbb R}$, with basis illustrated in the picture at the top of these notes. It’s a fine graphic - but for my money less useful than a clear representation of the algebra in terms of matrices over ${\mathbb R}$, ${\mathbb C}$ or ${\mathbb H}$.&lt;/p&gt;

&lt;p&gt;So (exercise!) - we can find isomorphisms
\[
Cl_{3,0} \cong {\mathbb H} \oplus {\mathbb H} 
\]
(where multiplication is componentwise) and
\[
Cl_{0,3} \cong {\mathbb C}(2) 
\]
(all $2 \times 2$ complex matrices). Again, one can learn (from data) and work with convolutional kernels taking values in either of these algebras.&lt;/p&gt;

&lt;p&gt;And so on for higher dimensions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7. A short zoo of applications&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The following list summarises some of the experiments and applications described in the references. It’s not complete, but I’ve separated the symmetries of the index space $I$ from those of the values taken by ${\bf x} : I \to V$.&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;
  &lt;tr&gt;
    &lt;th&gt;Application&lt;/th&gt;
    &lt;th&gt;Index space $I$&lt;/th&gt;
    &lt;th&gt;Value space $V$&lt;/th&gt;
    &lt;th&gt;Reference&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Image classification&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^2$ up to translation&lt;/td&gt;
    &lt;td&gt;${\mathbb R}$&lt;/td&gt;
    &lt;td&gt;[1]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Spherical images&lt;/td&gt;
    &lt;td&gt;${S}^2$ up to $SO(3)$&lt;/td&gt;
    &lt;td&gt;${\mathbb R}$&lt;/td&gt;
    &lt;td&gt;[3]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Signed volume of
     a polyhedron&lt;/td&gt;
    &lt;td&gt;$n$ indices&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^3$ up to $SO(3)$&lt;/td&gt;
    &lt;td&gt;[5]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Convex hull of points&lt;/td&gt;
    &lt;td&gt;$n$ indices up to $S_n$&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^5$ up to $O(5)$&lt;/td&gt;
    &lt;td&gt;[5]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;O(5)-invariant regression&lt;/td&gt;
    &lt;td&gt;{0,1}&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^5$ up to $O(5)$&lt;/td&gt;
    &lt;td&gt;[5]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$n$-body system&lt;/td&gt;
    &lt;td&gt;$n$ indices&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^3$ up to $E(3)$&lt;/td&gt;
    &lt;td&gt;[5]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Navier-Stokes PDE&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^2$ up to translation&lt;/td&gt;
    &lt;td&gt;${\mathbb R} \oplus {\mathbb R}^2$ up to $SO(2)$&lt;/td&gt;
    &lt;td&gt;[7]&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Maxwell&apos;s PDE&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^3$ up to translation&lt;/td&gt;
    &lt;td&gt;${\mathbb R}^3 \oplus {\mathbb R}^3$ up to $SO(3)$&lt;/td&gt;
    &lt;td&gt;[7]&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Ian Goodfellow, Yoshua Bengio, Aaron Courville, &lt;em&gt;Deep Learning&lt;/em&gt;, MIT Press (2016)&lt;/li&gt;
  &lt;li&gt;Taco Cohen, Max Welling, &lt;a href=&quot;https://arxiv.org/abs/1602.07576&quot; target=&quot;_blank&quot;&gt;Group equivariant convolutional networks&lt;/a&gt;, arXiv.1602.07576 (2016)&lt;/li&gt;
  &lt;li&gt;Taco S. Cohen, Mario Geiger, Jonas Koehler, Max Welling, &lt;a href=&quot;https://arxiv.org/abs/1801.10130&quot; target=&quot;_blank&quot;&gt;Spherical CNNs&lt;/a&gt;, arXiv.1801.10130 (2018)&lt;/li&gt;
  &lt;li&gt;Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Veličković, &lt;a href=&quot;https://arxiv.org/abs/2104.13478&quot; target=&quot;_blank&quot;&gt;Geometric Deep Learning: Grids, Groups, Graphs, Geodesics and Gauges&lt;/a&gt;, arXiv.2104.13478 (2021)&lt;/li&gt;
  &lt;li&gt;David Ruhe, Johannes Brandstetter, Patrick Forré, &lt;a href=&quot;https://arxiv.org/abs/2305.11141&quot; target=&quot;_blank&quot;&gt;Clifford group equivariant neural networks&lt;/a&gt;, arXiv.2305.11141 (2023)&lt;/li&gt;
  &lt;li&gt;David Ruhe, Jayesh K. Gupta, Steven de Keninck, Max Welling, Johannes Brandstetter, &lt;a href=&quot;https://arxiv.org/abs/2302.06594&quot; target=&quot;_blank&quot;&gt;Geometric Clifford algebra networks&lt;/a&gt;, arXiv.2302.06594 (2023)&lt;/li&gt;
  &lt;li&gt;Johannes Brandstetter, Rianne van den Berg, Max Welling, Jayesh K. Gupta, &lt;a href=&quot;https://arxiv.org/abs/2209.04934&quot; target=&quot;_blank&quot;&gt;Clifford neural layers for PDE modelling&lt;/a&gt;, arXiv.2209.04934 (2023)&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><category term="mathematics" /><summary type="html">Clifford group equivariance for ${\mathbb R}^3$. From [5].</summary></entry><entry><title type="html">Why mathematicians should care about Large Language Models</title><link href="http://localhost:4000/artificial_intelligence/mathematics/mathematics-vs-ai/" rel="alternate" type="text/html" title="Why mathematicians should care about Large Language Models" /><published>2024-01-05T00:00:00+00:00</published><updated>2024-01-05T00:00:00+00:00</updated><id>http://localhost:4000/artificial_intelligence/mathematics/mathematics-vs-ai</id><content type="html" xml:base="http://localhost:4000/artificial_intelligence/mathematics/mathematics-vs-ai/">&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-05/unicorn.png&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;&quot;Draw a unicorn in TikZ.&quot; Successive renderings by GPT-4, from [1]. Their relevance to the discussion will be revealed, all in good time.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This post is to review some remarkable observations by Microsoft and DeepMind researchers regarding the apparent ability of Large Language Models (LLMs) to solve mathematical problems. I believe mathematicians should sit up and take notice of these examples: we need at the very least to understand them - and to ask what they might mean for the future.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. A surprising example&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let’s start with a teaser - actually a version of a question from the 2022 International Mathematics Olympiad:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Suppose $g$ is a continuous smooth function such that for every $x &amp;gt; 0$, there is one and only one $y &amp;gt; 0$ such that $g(x) + g(y) ≤ 2xy$. Can you prove that $g(x) = x^2$?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you haven’t seen this before, I invite you to give it a little thought before proceeding.&lt;/p&gt;

&lt;p&gt;OK, thought about it enough? This is an example cited in a study of GPT-4 last year by Microsoft researchers [1 section 4.4]. It is put to GPT-4 as a prompt - here is the model’s response:&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-05/answer.png&quot; width=&quot;100%&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;What do we see? In principle, the chatbot is based on a sophisticated auto-complete - probabilistic next-word selection to construct a text response. Yet the result is some coherent reasoning which correctly solves the problem presented. Moreover, it’s not a standard problem: it would be surprising and challenging to most students.&lt;/p&gt;

&lt;p&gt;Conceivably, this same problem occured somewhere in the training corpus used to build the language model and GPT-4 is simply regurgitating a known answer - I’ll return to this possibility below. Yet this example is just one of many similarly jaw-dropping interactions with GPT-4 cited in [1]. Could they all have been in the training data?&lt;/p&gt;

&lt;p&gt;What is going on here?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. It’s Reinforcement Learning, stupid!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A base LLM is a sequence-to-sequence (&lt;a href=&quot;https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)&quot; target=&quot;_blank&quot;&gt;transformer&lt;/a&gt;) model built on a huge amount of text - typically 10s of billions of words - trawled from the Internet. It is built to model next-word probabilities based on long stretches of text. In this sense, it can be described as a very powerful ‘autocomplete’ capability.&lt;/p&gt;

&lt;p&gt;This does not tell the whole story, however. A base LLM alone would not be able to produce the kind of performance illustrated above. In a user-facing system such as GPT-4 there is much more going on, as introduced by OpenAI in [2] and explained in the excellent article by Aerin Kim [3].&lt;/p&gt;

&lt;p&gt;The magic that turns a base LLM into a high-performing, all-knowing chatbot is referred to as &lt;em&gt;Reinforcement Learning from Human Feedback&lt;/em&gt; (RLHF). In my view, this rather modest terminology doesn’t do justice to the cleverness of the design - though it does reveal that the most important ‘secret sauce’ is human input - lots of it, of high quality and meticulously managed.&lt;/p&gt;

&lt;p&gt;Briefly, the design consists to three machine learnt models:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;SFT model&lt;/strong&gt;. This stands for Supervised Fine Tuning, and is a further tuning of the parameters of the base LLM using ‘instruction data’ - which I’ll describe in just a moment.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reward model&lt;/strong&gt;. This is a second model which assigns a score to any pair &lt;em&gt;(prompt, response)&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Policy model&lt;/strong&gt;. This is a reinforcement-learnt model, which, given a text sequence, chooses a next-word (an ‘action’) with the goal of maximising the end-reward (as computed by the reward model).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s think about that for a moment. When GPT-4 responds to a user prompt, it is not simply auto-completing using next-word probabilities. What it is doing is more akin to game-playing: at each point in the game it has constructed a sequence of text (the current ‘state’); it is offered a choice of actions (the next word) based on probabilities given by the SFT model; it has to choose one of these actions in order to maximise the (future) reward of the final output.&lt;/p&gt;

&lt;p&gt;The success of the system comes from having, at each step, the best actions to choose from (thanks to the base LLM and the quality of the instruction data underlying the SFT model) and a reward signal (from 2) that accurately represents the expectations and needs of a user.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;instruction data&lt;/em&gt; used to train the SFT model consists of human curated pairs &lt;em&gt;(prompt, response)&lt;/em&gt;. The reward model, likewise, is trained on significant human input. For this, the training data consists of a large set of prompts (independent of those used for the SFT!), and selections of responses are ranked by human labellers.&lt;/p&gt;

&lt;p&gt;According to the discussion in [2,3], this human-generated input is not cheap, crowd-sourced data but follows detailed guidelines and is carefully choreographed. The performance of the system is critically dependent on the quality of this data and not on the power of the LLM alone.&lt;/p&gt;

&lt;p&gt;Back to mathematics. Examples like the one above suggest that LLMs can actually ‘do’ maths. What this is based on is models that are in effect compressions of data: of vast amounts of Internet data in the base LLM, but also of large amounts of human-curated data in the SFT and reward models.&lt;/p&gt;

&lt;p&gt;The question is, can the LLM do maths that it hasn’t seen before? Had the Olympiad solution at the top of this post been seen on the Internet, so that it was already present in the base LLM? Or could it have occured somewhere in the instruction data?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Can AI really discover new mathematics?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the recent paper [4], researchers at DeepMind found a brilliant way to test the general claim that one can indeed find completely new solutions to mathematical problems by consulting a LLM. (See also their blog post [5].)&lt;/p&gt;

&lt;p&gt;Namely, suppose we pick a problem for which progress can be directly evaluated for quality, and which is sufficiently well studied that the state-of-the-art is well established. Then, if we improve on that state-of-the-art using a LLM, we will have compelling evidence that the LLM has found novel mathematics.&lt;/p&gt;

&lt;p&gt;In [4] the authors pick the &lt;em&gt;cap set&lt;/em&gt; and &lt;em&gt;bin packing&lt;/em&gt; problems to study. &lt;a href=&quot;https://en.wikipedia.org/wiki/Bin_packing_problem&quot; target=&quot;_blank&quot;&gt;Bin packing&lt;/a&gt; - that is, fitting a collection of variable-sized objects into the smallest number of fixed-sized bins - is well known and ubiquitous in computer science for tasks such as resource allocation. The methods of [4] - which I’ll explain in a moment - are applied to some standard benchmark data sets for bin packing, and in all cases beat previous known methods.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Cap_set&quot; target=&quot;_blank&quot;&gt;cap set&lt;/a&gt;
problem is less well known outside of number theory and extremal combinatorics. To state the problem baldly: a &lt;em&gt;cap set&lt;/em&gt; is a subset $S \subset {\mathbb F}_3^n$ with no three points collinear - or equivalently no three points adding to $0 \in {\mathbb F}_3^n$. (I’m writing ${\mathbb F}_3 = {\mathbb Z}/3$ for the field with 3 elements.)&lt;/p&gt;

&lt;p&gt;Then, for each $n$, what is the largest possible size $s_n$ of a cap set?&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2024-01-05/gridw.png&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption&gt;The grid ${\mathbb F}_3^n$ for $n = 2$. The shaded yellow vertices are a cap set. From Wikipedia.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;For example, the figure illustrates $s_2 = 4$. As an exercise, you might be able to see (by drawing some pictures) that $s_3 = 9$.
Here are &lt;a href=&quot;https://oeis.org/A090245&quot; target=&quot;_blank&quot;&gt;a few more values&lt;/a&gt;. But for most $n$, the exact value of $s_n$ is not known, and the game is mainly to improve on known bounds and asymptotics.&lt;/p&gt;

&lt;p&gt;Well, it won’t surprise you that the authors of [4], using their LLM methods, improve on previously known results for $s_n$. In particular, for $n=8$ they improve the previously best known result $s_8 \geq 496$ to $s_8 \geq 512$.&lt;/p&gt;

&lt;p&gt;Just before coming to the LLM methods behind this, why is the cap set problem interesting? I feel this needs a few words of background.&lt;/p&gt;

&lt;p&gt;The story starts with the relationship betwen the &lt;em&gt;prime numbers&lt;/em&gt; $2,3,5,7,11,\ldots$ and &lt;em&gt;arithmetic progressions&lt;/em&gt; (APs) (whole number sequences of the form $a, a+d, a+2d,a+3d, \ldots$). A long time ago Dirichlet showed that every (infinite) AP with $a,d$ coprime contains infinitely many primes. In 2004, Green and Tao proved a sort of converse, that the sequence of primes contains arbitrarily long finite APs.&lt;/p&gt;

&lt;p&gt;(For example $3,5,7$ is an AP of length 3. Here’s an exercise: find APs in the primes of lengths 4,5,…)&lt;/p&gt;

&lt;p&gt;It is generally believed that this property results from the &lt;em&gt;density&lt;/em&gt; of the primes in ${\mathbb N}$ as they go to infinity. Let’s say a subset $A \subset{\mathbb N}$ is &lt;em&gt;dense&lt;/em&gt; if $\sum_{n \in A} 1/n = \infty$. Erdős had shown that the prime numbers are dense in this sense - and he conjectured that this property of being dense is enough to force $A$ to contain arbitrarily long APs.&lt;/p&gt;

&lt;p&gt;Proving this conjecture turns out to be a hard problem. In fact, even the special case of APs of length 3 is not known. That is, if $A \subset {\mathbb N}$ is dense, does it necessarily contain a 3-term AP ${a, a+d, a+2d}$? Even this is not known!&lt;/p&gt;

&lt;p&gt;The cap set problem arises from studying this 3-term case of the Erdős conjecture. Suppose that instead of looking at ${1,\ldots, N}$ as $N \to \infty$ we were looking at ${\mathbb F}_3^n$ as $n \to \infty$. (And it turns out that some arguments can be mapped between these two spaces.) Then a 3-term AP in ${\mathbb F}_3^n$ is exactly a line, and a subset $A$ without 3-term APs is a cap set. So the Erdős conjecture translates to a statement that a sufficiently dense subset must contain lines. To quantify this we need to understand how big a cap set can be.&lt;/p&gt;

&lt;p&gt;Well, end of digression. If you needed convincing, this is roughly why the cap set problem is of interest to number theorists.&lt;/p&gt;

&lt;p&gt;So back to the point: the DeepMind researchers were able to generate demonstrably new mathematical results. How exactly did they use an LLM to do this?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Using LLM as a search tool&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LLMs exhibit powerful capability to generate not just natural language text but also computer code - and code in response to natural language prompts. Take a look, for example, at the graphic at the top of this post. The unicorn pictures shown are the compiled images from &lt;a href=&quot;https://en.wikipedia.org/wiki/PGF/TikZ&quot; target=&quot;_blank&quot;&gt;TikZ&lt;/a&gt; code output by GPT-4.&lt;/p&gt;

&lt;p&gt;The DeepMind work [4] has two key novelties. The first is that it approaches the problems &lt;em&gt;bin packing&lt;/em&gt; and &lt;em&gt;cap set&lt;/em&gt; by asking the LLM not just for solutions, but for code to generate a solution. The LLM used here, incidentally, is not GPT-4 but Google’s specialist &lt;a href=&quot;https://lablab.ai/tech/google/codey&quot; target=&quot;_blank&quot;&gt;Codey&lt;/a&gt; model.&lt;/p&gt;

&lt;p&gt;So, for example, the model is not asked &lt;em&gt;‘what is the largest cap set you can find in ${\mathbb F}_3^n$?’&lt;/em&gt; but rather &lt;em&gt;‘give me Python code to do the following …‘&lt;/em&gt; More precisely, it is asked to complete a code template in which a particular function is to be filled in. For the cap set problem the template implements a greedy algorithm for building a cap set point by point, and the model is asked to fill in the crucial priority function that scores each candidate point for inclusion.&lt;/p&gt;

&lt;p&gt;It goes without saying that this is a much more interpretable use of the AI: the code returned can be examined, understood and can inform subsequent mathematical analysis.&lt;/p&gt;

&lt;p&gt;The second key novelty is that the LLM is not used for a single query, but for a sequence of queries, each of which seeks to improve on previous answers. So each query is not &lt;em&gt;‘fill in the priority function in this code template’&lt;/em&gt;, but rather, &lt;em&gt;‘given versions v0, v1 of the priority function in this code template, what should version v2 be?’&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The LLM is thus used not for one-time query but as an oracle step in an iterative algorithm. The full algorithm is evolutionary in the sense that a population of highest-performing codes is maintained, and the LLM prompts (the code versions &lt;em&gt;v0,v1&lt;/em&gt; etc) are drawn from this population.&lt;/p&gt;

&lt;p&gt;The details of DeepMind’s evolutionary approach - their use of the LLM to develop a code to solve the original mathematical problem - are themselves very interesting. There’s no need for me to say more about them here as that is much better done in the blog [5] (and in [4]).&lt;/p&gt;

&lt;p&gt;But the work sends a signal to the mathematical community, in my opinion, that there are very powerful new tools for us coming from language modelling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Sébastien Bubeck et al, &lt;em&gt;Sparks of Artificial General Intelligence: Early experiments with GPT-4&lt;/em&gt;, &lt;a href=&quot; https://doi.org/10.48550/arXiv.2303.12712&quot; target=&quot;_blank&quot;&gt;arXiv.2303.12712&lt;/a&gt; (2023)&lt;/li&gt;
  &lt;li&gt;Long Ouyang et al, &lt;em&gt;Training language models to follow instructions with human feedback&lt;/em&gt;, &lt;a href=&quot; https://doi.org/10.48550/arXiv.2203.02155&quot; target=&quot;_blank&quot;&gt;arXiv.2203.02155&lt;/a&gt; (2022)&lt;/li&gt;
  &lt;li&gt;Aerin Kim, &lt;a href=&quot;https://medium.com/towards-data-science/rlhf-reinforcement-learning-from-human-feedback-faa5ff4761d1&quot; target=&quot;_blank&quot;&gt;RLHF: Reinforcement Learning from Human Feedback&lt;/a&gt; Medium (2023)&lt;/li&gt;
  &lt;li&gt;Romera-Paredes, B., Barekatain, M., Novikov, A. et al, &lt;em&gt;Mathematical discoveries from program search with large language models&lt;/em&gt; &lt;a href=&quot;https://doi.org/10.1038/s41586-023-06924-6&quot; target=&quot;_blank&quot;&gt;https://doi.org/10.1038/s41586-023-06924-6&lt;/a&gt;, Nature (2023)&lt;/li&gt;
  &lt;li&gt;A. Fawzi, B. Romera Paredes, &lt;a href=&quot;https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/&quot; target=&quot;_blank&quot;&gt;FunSearch: Making new discoveries in mathematical sciences using Large Language Models&lt;/a&gt;, Google DeepMind blog, December 2023.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="artificial_intelligence" /><category term="mathematics" /><summary type="html">&quot;Draw a unicorn in TikZ.&quot; Successive renderings by GPT-4, from [1]. Their relevance to the discussion will be revealed, all in good time.</summary></entry><entry><title type="html">Neural networks in single-celled organisms</title><link href="http://localhost:4000/artificial_intelligence/wetware/" rel="alternate" type="text/html" title="Neural networks in single-celled organisms" /><published>2023-11-15T00:00:00+00:00</published><updated>2023-11-15T00:00:00+00:00</updated><id>http://localhost:4000/artificial_intelligence/wetware</id><content type="html" xml:base="http://localhost:4000/artificial_intelligence/wetware/">&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/ecoli_size.jpg&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;Source: &lt;a href=&quot;https://www.uq.edu.au/news/article/2022/01/scientists-uncover-resistance-gene%E2%80%99-deadly-e-coli&quot; target=&quot;_blank&quot;&gt;University of Queensland&lt;/a&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;We tend to think of biological intelligence as arising from animal nervous systems and brains. But consider this. The bacterium &lt;a href=&quot;https://en.wikipedia.org/wiki/Escherichia_coli&quot; target=&quot;_blank&quot;&gt;Escherichia coli&lt;/a&gt;  pictured above is about 0.5 micron across. Thousands could sit in the cross-section of a human hair. Notably, 0.5 micron is about the same size as a single synapse connecting neurons in the brain. Yet this bacterium can process information, exhibits short-term memory and makes decisions. It has to do so, as does every organism, in order to survive.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/dendrites_marked.png&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;Source: &lt;a href=&quot;https://openbooks.lib.msu.edu/neuroscience/chapter/the-neuron/&quot; target=&quot;_blank&quot;&gt;Foundations of Neuroscience, Michigan State University&lt;/a&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This blog post is inspired by, and heavily draws upon, Dennis Bray’s beautiful 2009 book &lt;em&gt;Wetware&lt;/em&gt; [2], which describes how this information processing works (following [1]). The vast majority of organisms do not have nervous systems or brains, and yet they are able to exhibit biological ‘intelligence’. The biggest surprise for me in Bray’s account is how the molecular information processing that takes place in the cell can be modelled as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_neural_network&quot; target=&quot;_blank&quot;&gt;neural network&lt;/a&gt; in the same sense as understood in computer science. The units of the network are not nerve cells as we think of for animals (including humans), but are &lt;a href=&quot;https://en.wikipedia.org/wiki/Protein&quot; target=&quot;_blank&quot;&gt;proteins&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, although artificial neural networks (ANNs) were originally inspired by the human brain, they are inevitably too coarse a model to represent what really goes on in the brain. In the machine learning community we understand that. We know that we’re not really modelling brains, but that ANNs are still a powerful computational device nonetheless - and underpin most of modern AI.&lt;/p&gt;

&lt;p&gt;What is much less well known is that ANNs as a model are also a way to represent protein-protein interactions (PPIs) in the cell – and probably a much closer model of this than they are of animal brains.&lt;/p&gt;

&lt;p&gt;A question it seems ripe to ask is: what lessons might this observation have for Artificial Intelligence?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Clever cells: finding biological intelligence in microbes.&lt;/li&gt;
    &lt;li&gt;Protein networks: how proteins implement neural networks in the cell.&lt;/li&gt;
    &lt;li&gt;Lessons for AI: Artificial Intelligence has long drawn inspiration from biology - what can we learn from cell intelligence?&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;1. Clever cells&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An &lt;em&gt;E.coli&lt;/em&gt; bacterium is an autonomous agent (to use the language of AI!) moving in a fluid medium. Its method of locomotion is to rotate its ‘tail’, made up of a number of flagellae, each driven at about 100 Hz by a small molecular motor. The bacterium has two modes of motion: most of the time, all its motors rotate in the same direction, driving it at an approximately constant velocity in one direction. However, the bacterium can decide to reverse the direction of one or more of its motors, in which case it adopts an irregular ‘tumble’.&lt;/p&gt;

&lt;p&gt;The bacterium also has molecular sense organs, which can detect up to 50 different chemical compounds at concentrations of just 1 part in 10 million. Some of these (e.g. sugars) it wants to steer towards; others (toxins) it wants to avoid. Evolution has equipped &lt;em&gt;E.coli&lt;/em&gt; with information processing mechanisms (which I’ll come to in a moment) that allow it to detect chemical gradients and adjust its motion to increase concentrations of food and decrease the presence of toxins.&lt;/p&gt;

&lt;p&gt;Over periods of sustained travel interspersed with tumbling in a viscous medium, the bacterium must regularly update its environmental assessment. In order to detect chemical gradients, it must both estimate concentrations and compare these with previous estimates. For this it needs some form of short-term memory.
It must make decisions based on trade-offs between different (good and bad) chemicals present, and based on its current state of hunger, avoidance of threat etc.&lt;/p&gt;

&lt;p&gt;Bacteria like &lt;em&gt;E.coli&lt;/em&gt; have mechanisms to process information and convert sensory inputs (plus current internal state) into motor outputs, to achieve survival and reproduction in the competitive struggle with other organisms in the environment. They have clearly been successful in this over most of 3 billion years.&lt;/p&gt;

&lt;p&gt;One can assume that their bevaviours are hard-wired by evolution (much like the bots I wrote about in an earlier post &lt;a href=&quot;https://billoxbury.github.io/artificial_intelligence/zombie-bots-and-neural-bots/&quot; target=&quot;_blank&quot;&gt;Zombie bots and neural bots&lt;/a&gt;). More sophisticated microbes, on the other hand, also show evidence of &lt;em&gt;learning&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Protozoa&lt;/em&gt; are single-celled eukaryotes (cells with a nucleus) and are some orders of magnitude larger than bacteria such as &lt;em&gt;E.coli&lt;/em&gt;. One of the best known, for example, is &lt;em&gt;Amoeba proteus&lt;/em&gt;, a large predatory protozoan that hunts bacteria and other small organisms. Its mode of transport is different from the swimming of &lt;em&gt;E.coli&lt;/em&gt; - it stretches out ‘arms’ called &lt;em&gt;pseudopodia&lt;/em&gt;, via cytoplasmic streaming, and changing its whole body shape by flowing into one or more of these pdeudopodia.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/amoeba_proteus_scale.jpg&quot; width=&quot;100%&quot; /&gt;
  &lt;figcaption&gt;
  Source: &lt;a href=&quot;https://en.wikipedia.org/wiki/Amoeba&quot; target=&quot;_blank&quot;&gt;Wikipedia&lt;/a&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Amoeba&lt;/em&gt; feeds by pursuing and ingesting prey which may itself be in motion. To do this, it needs to detect the location and movement of that prey. It needs to adapt its behaviour and mode of locomotion according to type of prey, and to coordinate multiple pseudopodia, both in the pursuit and to surround and engulf its prey.&lt;/p&gt;

&lt;p&gt;Protozoa such as &lt;em&gt;Amoeba&lt;/em&gt; respond to chemical gradients, mechanical vibrations, light, temperature, gravity. In other words, they exhibit sensory capability and &lt;em&gt;attention&lt;/em&gt;. As they respond to their environmental state and
move between distinct states of activity (feeding, travelling, resting, dividing etc), these creatures demonstrate responsiveness to the same range of sensory inputs as multi-celled animals, and the ability to make decisions on appropriate motor outputs. But without any nervous system!&lt;/p&gt;

&lt;p&gt;It’s interesting to note in passing that &lt;em&gt;individuality&lt;/em&gt; of behaviour is observed by researchers - with each bacterium (this is from [2], referring to &lt;em&gt;E.coli&lt;/em&gt;) “displaying a distinct pattern of swimming”! This shouldn’t surprise us as random variation is the basis of evolution by natural selection. We also observe it in much simpler simulated systems too (see the &lt;a href=&quot;https://billoxbury.github.io/artificial_intelligence/zombie-bots-and-neural-bots/&quot; target=&quot;_blank&quot;&gt;earlier blog&lt;/a&gt; mentioned above).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Associative learning&lt;/em&gt; - that is, an organism’s ability to change its response to a given stimulus in the light of experience - is something we usually associate with brainy animals. However, it turns out there there is a long literature claiming associative learning in various protozoa including &lt;em&gt;Amoeba&lt;/em&gt;. Many examples can be found in the references [3,4,5].&lt;/p&gt;

&lt;p&gt;In summary, we can say that in evolutionary terms, biological information processing predated the evolution of nerve cells, nervous systems and brains by about 3 billion years. Not only that, but the capability of biological organisms to &lt;em&gt;learn&lt;/em&gt; preceded nervous systems by maybe 1 billion years. In other words, brains and nervous systems are not actually &lt;em&gt;fundamental&lt;/em&gt; to biological intelligence. Understanding what is could be illuminating for those of us thinking about artificial intelligence.&lt;/p&gt;

&lt;p&gt;It turns out that the answer still seems to involve neural networks!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Protein networks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In this section I want to summarise Bray’s account in [1,2] of how information processing works in a cell to achieve the coordination, decision-making and even learning that we’ve seen above in bacteria and protozoa. The very surprising punchline is that the biochemical mechanisms we describe can be framed as instances of neural networks, in the sense of mathematical &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_neural_network&quot; target=&quot;_blank&quot;&gt;Artificial Neural Networks&lt;/a&gt; (ANNs). (And I’m going to assume the reader is familiar with these.)&lt;/p&gt;

&lt;p&gt;The key players are the &lt;a href=&quot;https://en.wikipedia.org/wiki/Protein&quot; target=&quot;_blank&quot;&gt;proteins&lt;/a&gt;. Each protein molecule is built from a chain of amino acid molecules joined together - drawn from an ‘alphabet’ of 20 building block amino acids. The 20 amino acids have pairwise attractive and repulsive tendencies, and this causes a characteristic folding pattern of each protein molecule. This folding leads to the protein molecule having a geometry which may have &lt;em&gt;binding sites&lt;/em&gt; that can connect to other proteins.&lt;/p&gt;

&lt;p&gt;How do proteins interact? There are two fundamental physical mechanisms we need to understand:&lt;/p&gt;

&lt;p&gt;The first is &lt;em&gt;thermal diffusion&lt;/em&gt;, that is, Brownian motion by which molecules are randomly moving around the cell under heat energy, ricocheting off other molecules. The &lt;a href=&quot;http://book.bionumbers.org/what-are-the-time-scales-for-diffusion-in-cells/&quot; target=&quot;_blank&quot;&gt;time scales&lt;/a&gt; for this are small: the time for a protein molecule to traverse an &lt;em&gt;E.coli&lt;/em&gt; cell is around 10 milliseconds, or 100 times/sec.&lt;/p&gt;

&lt;p&gt;When we speak of a protein $P$ in a cell we mean, more precisely, the population of all $P$-molecules in that cell. This may be in the region $10^4$-$10^6$ molecules. So under thermal diffusion, molecules of two proteins $P$ and $Q$ can be expected to meet many thousands of times per second.&lt;/p&gt;

&lt;p&gt;The second physical mechanism to mention is what happens when molecules of two proteins $P,Q$ meet. In this event, one or other molecule can attach to binding sites of the other, via affinity of amino acids in the respective geometries.&lt;/p&gt;

&lt;p&gt;In general, stable molecular structures in the cell are formed and maintained by ‘strong’ bonds (the making and breaking of which requires a significant transfer of energy). Protein interactions, on the other hand, are usually constructed by ‘weak’ bonds and geometric ‘recognition’. The strength of such a bond depends on the geometric goodness of fit.&lt;/p&gt;

&lt;figure style=&quot;width:75%&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/1qha.gif&quot; /&gt;
  &lt;figcaption&gt;
  Source: &lt;a href=&quot;https://proteopedia.org/wiki/index.php/Hexokinase&quot; target=&quot;_blank&quot;&gt;Protopedia&lt;/a&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;What I’ve described so far, at the most basic level, is how protein-protein interactions (PPIs) work. Just to illustrate the ‘social network’ of these, the following graph shows 2,234 binary interactions (edges of the graph) among 1,269 proteins (vertices) from the PPI network in &lt;em&gt;E.coli&lt;/em&gt;:&lt;/p&gt;

&lt;figure style=&quot;width:100%&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/ecoli_ppi_notext.png&quot; /&gt;
  &lt;figcaption&gt;
  Source: &lt;a href=&quot;https://www.nature.com/articles/nbt.2831&quot; target=&quot;_blank&quot;&gt;Nature&lt;/a&gt;, reference [6]
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The next thing to describe is how PPIs - weak binding of proteins through thermal diffusion and geometric recognition - leads to signals which allow propagation of information across a cell.&lt;/p&gt;

&lt;p&gt;The key to this is that a protein molecule can exist in more than one (geometric) state. Recalling that the folding geometry of a protein $P$ depends on the net effect of mutual affinities of the amino acids in the constituent chain, it’s easy to see that in the presence of a binding protein $Q$ this total effect can change, so that the geometry of $P$ jumps to a different configuration. In this new configuration, new binding properties may appear, switching on or off interactions with other proteins.&lt;/p&gt;

&lt;p&gt;The following diagram is taken from [2] directly, and shows a protein which functions as an enzyme (converting $A$ to $A’$) but under regulation by protein $B$. It has the signalling effect of a transistor:&lt;/p&gt;

&lt;figure style=&quot;width:75%&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/transistor.jpg&quot; /&gt;
  &lt;figcaption&gt;
  Source: reference [2] page 67.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To quote directly from [2]:&lt;/p&gt;

&lt;p&gt;&lt;small&gt;Two-state proteins are everywhere in a living cell ... they are the building blocks of flagella and cilia ... the molecular motors that harness chemical energy to make a cell divide, a muscle contract, an amoeba crawl ... They are at the heart of the electrical signals produced by nerve cells in our brain and hence underpin all our mental activities.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Some protein switches are held in ‘solid state’, for increased sensitivity or amplification, or for mechanical reasons. This includes the chemical receptors (signalling across the cell membrane) and the motors (which spin the flagella) in &lt;em&gt;E.coli&lt;/em&gt;:&lt;/p&gt;

&lt;figure style=&quot;width:75%&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/ecoli_machine.jpg&quot; /&gt;
  &lt;figcaption&gt;
  Source: reference [2] page 91.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This diagram illustrates a general principle: any organism, to be independently mobile, must have sensory organs, some internal processing of those signals, and motor outputs that determine physical movement.&lt;/p&gt;

&lt;p&gt;Detection of environmental signals is performed by receptors - protein switches embedded in the external cell membrane as shown above. Cells have hundreds of different kinds of receptors. Switching of a receptor by its target chemical on the outside of the cell activates its molecular function, initiating a chain of PPIs inside the cell.&lt;/p&gt;

&lt;p&gt;(Inevitably, I’m skipping over lots of more complex detail. In particular, this includes efficiencies achieved by regulation of ‘third party’ background PPIs such as &lt;em&gt;kinase-phosphatase cycles&lt;/em&gt;. But these all fall within the overall dynamical system of PPIs operating in the cell.)&lt;/p&gt;

&lt;p&gt;Let’s turn to the internal processing - the decision making that processes the sensory signal and controls the operation of the motor proteins - how does this work?&lt;/p&gt;

&lt;p&gt;Bray explicitly recognises that the cell PPIs can be interpreted as a neural network, and illustrates the possible congurations of inputs/outputs with the following figure:&lt;/p&gt;

&lt;figure style=&quot;width:75%&quot; class=&quot;align-center&quot;&gt;
  &lt;img src=&quot;/assets/img/2023-11-15/processing.jpg&quot; /&gt;
  &lt;figcaption&gt;
  Source: reference [2] page 81.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The modelling of each (protein) unit $P$ as a perceptron is explained in more detail in [1]. The inputs to $P$, at any point in time, are the concentrations of its incoming regulators. These are weighted by their catalytic efficiency as determined by binding strengths and other factors. The activation function is typically sigmoidal and the output of $P$ is its concentration at that time.&lt;/p&gt;

&lt;p&gt;The network architeture is far from layered or feed-forward, but is inherently &lt;em&gt;recurrent&lt;/em&gt;, including complex cyclic catalytic relationships among groups of proteins.&lt;/p&gt;

&lt;p&gt;Of course, all models are simplifications and this is no exception. Units in the network are not all alike in their behaviours: each protein has its own characteristics including timescale of reaction and 
non-uniformity of distribution in the cell. Thermal diffusion operates at different timescales for smaller molecules compared to larger molecules; and proteins may exhibit localisation near, or impedance by, large-scale structures within the cell such as vesicles, filaments and membranes. So a good model might include per-unit parameters to allow for such factors.&lt;/p&gt;

&lt;p&gt;What is the training process for a molecular neural network?&lt;/p&gt;

&lt;p&gt;By far the most important training signal comes from the evolution of PPIs through natural selection. On the other hand, we’ve seen that cells can learn, and so there must also be mechanisms by which the weights of the network (rates of catalytic efficiency) can change in response to stimuli, allowing reinforcement learning. In multi-cellular organisms this is seen, for example, in cells of the nervous system and the immune system. Bray discusses some molecular mechanisms by which this may work - but I won’t discuss these here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Lessons for AI&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Most of us, learning for the first time about artificial neural networks (ANNs), were introduced to them as a simplified model of neurons in the brain. Research in AI and in algorithms has derived huge benefit from &lt;a href=&quot;https://en.wikipedia.org/wiki/Bio-inspired_computing&quot; target=&quot;_blank&quot;&gt;imitating biology&lt;/a&gt;, and neural networks have been one of the most successful examples.&lt;/p&gt;

&lt;p&gt;However, what the work of Bray and others shows is that the ANN model has even greater depth and significance in biology than we realised. What conclusions should AI researchers draw from this?&lt;/p&gt;

&lt;p&gt;One question to consider is the evolutionary relationship between molecular neural networks in single cells and multi-celled nervous systems in animals. Did the latter evolve independently and by coincidence? Almost certainly not: it turns out that key (PPI) signalling pathways that control motor behaviour in bacteria and protozoa were co-opted by evolution for use in the firing of action potentials between nerve cells. These collectively determine the computational processes in the brain.&lt;/p&gt;

&lt;p&gt;Consider this: a single dendritic spine - just one of a nerve cell’s 1000s of receptors for incoming axons - is about the size of a bacterium and operates, like a bacterium, by having a complex of receptor proteins embedded in its membrane. When the incoming axon fires, these receptors detect the neurotransmitter glutamate crossing the synapse. Some of the receptors can additionally detect the change of voltage within the spine that occurs when the receiving cell fires. This in turn can regulate an increase in sensitivity of that dendritic spine, driving a process of &lt;a href=&quot;https://en.wikipedia.org/wiki/Hebbian_theory&quot; target=&quot;_blank&quot;&gt;Hebbian learning&lt;/a&gt; for the formation of long-term memories in the brain.&lt;/p&gt;

&lt;p&gt;In effect, evolution has adapted ancient and successful signalling PPIs to solve the problem of &lt;em&gt;scaling&lt;/em&gt; - at least in animals. That is, the basic processes of thermal diffusion and geometric recognition of molecules are no longer sufficient for information processing at the length scales of multicellular organisms.&lt;/p&gt;

&lt;p&gt;(Indeed, this raises a fascinating question for plants and fungi: these multi-cellular organisms must also process environmental information, and the mechanisms for this can also be expected to be derived from ancestral single-cell PPIs. Can their (macroscopic) solutions likewise be modelled as neural networks?)&lt;/p&gt;

&lt;p&gt;So here is the bad news for AI. As long as we seek to model anything of the complexity of the human brain (or of animal intelligence more generally), artificial neural networks, even at the scale of current deep learning systems and large language models - and despite their success on the problems for which they are designed - can be expected to be fundamentally inadequate.&lt;/p&gt;

&lt;p&gt;To highlight this point, I cannot do better than quote again from [2]. He points out that animal nerve cells are “self-contained entities … each a molecular metropolis in its own right”, and goes on to observe:&lt;/p&gt;

&lt;p&gt;&lt;small&gt; Imprisoned in the crowded confines of the cortex, your [brain] cells have no opportunity to escape. But there is nothing to stop them moving in place. They can grow and shrink, extend or retract their dendrites or branches of their axons. Their synaptic spines can be ... just as dynamic as an amoeba&apos;s pseudopodia. The movements of a nerve cell in the brain may be of shorter duration and harder to observe than those of a free-living cell, but why should they be less well informed? The milieu of such a cell is a rich and ever-changing broth of ions and neurotransmitters. There has been every opportunity for nerve cells evolving over millennia to learn how to extract information from this chemical soup.
&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Here’s the good news. The model of artificial neural networks, stumbled upon as a huge but very happy over-simplification of animal brains, turns out to be more fundamental in biology than we realised. It should be no coincidence, then, that it’s been so successful on such a broad range of hard tasks.&lt;/p&gt;

&lt;p&gt;But evolving ANNs to models that get closer to &lt;a href=&quot;https://en.wikipedia.org/wiki/Artificial_general_intelligence&quot; target=&quot;_blank&quot;&gt;AGI&lt;/a&gt; will likely benefit from a more subtle understanding of biological intelligence.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Dennis Bray, &lt;em&gt;Protein molecules as computational elements in living cells&lt;/em&gt;, &lt;a href=&quot;https://doi.org/10.1038/376307a0&quot; target=&quot;_blank&quot;&gt;Nature 376, 307–312&lt;/a&gt; (1995)&lt;/li&gt;
  &lt;li&gt;Dennis Bray, &lt;em&gt;Wetware, A Computer in Every Cell&lt;/em&gt;, Yale University Press (2009)&lt;/li&gt;
  &lt;li&gt;Philip Applewhite, &lt;a href=&quot;https://books.google.co.uk/books?hl=en&amp;amp;lr=&amp;amp;id=SznlULZ3hi0C&amp;amp;oi=fnd&amp;amp;pg=PA341&amp;amp;dq=learning+in+protozoa&amp;amp;ots=AjJ1310une&amp;amp;sig=ZtGWboHuutf2BXBDqGWg2QJCjhk&amp;amp;redir_esc=y#v=onepage&amp;amp;q=learning%20in%20protozoa&amp;amp;f=false&quot; target=&quot;_blank&quot;&gt;Learning in protozoa&lt;/a&gt;, Biochemistry and physiology of protozoa (1979)&lt;/li&gt;
  &lt;li&gt;De la Fuente, I.M., Bringas, C., Malaina, I. et al. &lt;em&gt;Evidence of conditioned behavior in amoebae&lt;/em&gt;,  &lt;a href=&quot;https://doi.org/10.1038/s41467-019-11677-w&quot; target=&quot;_blank&quot;&gt;Nat Commun 10, 3690&lt;/a&gt; (2019)&lt;/li&gt;
  &lt;li&gt;Samuel Gershman, Petra Balbi, Randy Gallistel, Jeremy Gunawardena, &lt;em&gt;Reconsidering the evidence for learning in single cells&lt;/em&gt; &lt;a href=&quot;https://doi.org/10.7554/eLife.61907&quot; target=&quot;_blank&quot;&gt;eLife 10:e61907&lt;/a&gt; (2021)&lt;/li&gt;
  &lt;li&gt;Rajagopala, S., Sikorski, P., Kumar, A. et al., &lt;em&gt;The binary protein-protein interaction landscape of Escherichia coli.&lt;/em&gt; &lt;a href=&quot;https://doi.org/10.1038/nbt.2831&quot; target=&quot;_blank&quot;&gt;Nat Biotechnol 32, 285–290&lt;/a&gt; (2014)&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="artificial_intelligence" /><summary type="html">Source: University of Queensland</summary></entry><entry><title type="html">Predicting the rank of an elliptic curve</title><link href="http://localhost:4000/mathematics/predicting-elliptic-curve-rank/" rel="alternate" type="text/html" title="Predicting the rank of an elliptic curve" /><published>2023-10-27T00:00:00+00:00</published><updated>2023-10-27T00:00:00+00:00</updated><id>http://localhost:4000/mathematics/predicting-elliptic-curve-rank</id><content type="html" xml:base="http://localhost:4000/mathematics/predicting-elliptic-curve-rank/">&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/tsne.png&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of all the hype that attaches to machine learning these days, among the least trumpeted applications - but to my mind some of the most interesting - are those applications of machine learning to mathematics itself. In this post I want to talk about an application demonstrated in the paper [1] &lt;a href=&quot;https://doi.org/10.48550/arXiv.2204.10140&quot; target=&quot;_blank&quot;&gt;Murmurations of elliptic curves&lt;/a&gt;. I will discuss some experiments of my own reproducing the results of that paper.&lt;/p&gt;

&lt;p&gt;Spoiler for the graphic above: each dot represents an elliptic curve over ${\mathbb Q}$ coloured by the rank of the curve; its position in the plane depending only on the numbers of points on the curve modulo the first 100 prime numbers. (I’ll explain all this as we go!)&lt;/p&gt;

&lt;p&gt;The subject requires quite a bit of background, but it’s a story worth telling: it relates closely to a problem, the &lt;em&gt;Birch-Swinnerton-Dyer Conjecture&lt;/em&gt;, which is one of the seven $1,000,000 &lt;a href=&quot;https://en.wikipedia.org/wiki/Millennium_Prize_Problems&quot; target=&quot;_blank&quot;&gt;Millennium Prize Problems&lt;/a&gt; announced by the Clay Mathematics Institute in 2000.&lt;/p&gt;

&lt;p&gt;Let’s start with:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is an elliptic curve?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An &lt;a href=&quot;https://en.wikipedia.org/wiki/Elliptic_curve&quot; target=&quot;_blank&quot;&gt;elliptic curve&lt;/a&gt; is essentially a plane curve defined by a cubic equation in coordinates $x,y$, for example
\[
y^2 + xy + y = x^3 - x^2 - 9916x - 377564.
\]
The coefficients can be any real or complex numbers, but in this post I’m only concerned with curves with coefficients in the rational numbers ${\mathbb Q}$, as in this example. These are called elliptic curves over ${\mathbb Q}$.&lt;/p&gt;

&lt;p&gt;Elliptic curves have both a long mathematical history and a surprising modern relevance - both on account of the fact that points on the curve naturally form a &lt;em&gt;group&lt;/em&gt;, via the rule that three points are collinear in the plane if and only if they add to zero in the group law:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/grouplaw.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(The identity element $O_E$ is usually taken to be the point at infinity on the $y$-axis.)&lt;/p&gt;

&lt;p&gt;The modern relevance of this is the use of elliptic curve groups in &lt;a href=&quot;https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm&quot; target=&quot;_blank&quot;&gt;digital security&lt;/a&gt;. The mathematical relevance is in understanding the structure of this group for any given curve. (And, of course, the mathematical theory is critical for the secure use of elliptic curves in encryption and signature schemes.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the rank?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The rational points on an elliptic curve $E$, which we denote by $E({\mathbb Q})$, form an &lt;em&gt;abelian group&lt;/em&gt; - that is, the group is commutative $P + Q = Q + P$. Moreover, the &lt;em&gt;Mordell-Weil Theorem&lt;/em&gt;, proved in the 1920s, says that this group is &lt;em&gt;finitely generated&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;(Notice that I’ve specified points in the rational field ${\mathbb Q}$. If I’d said points in the complex field ${\mathbb C}$, the theorem would not be true - in fact the group $E({\mathbb C})$ is isomorphic to a &lt;em&gt;torus group&lt;/em&gt; $S^1 \times S^1$. So the field matters! Most of what I’ll say below is true for any &lt;em&gt;algebraic number field&lt;/em&gt; - but I want to keep things simple and only talk about curves over ${\mathbb Q}$.)&lt;/p&gt;

&lt;p&gt;So $E({\mathbb Q})$ is a finitely generated abelian group. This means that the group must be isomorphic to&lt;/p&gt;

&lt;p&gt;\[
{\mathbb Z}^r \oplus E({\mathbb Q})_{\rm torsion}
\]&lt;/p&gt;

&lt;p&gt;where the torsion part is a finite group and the number $r$ is called the &lt;em&gt;rank&lt;/em&gt; of the group.&lt;/p&gt;

&lt;p&gt;Computing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rank_of_an_elliptic_curve&quot; target=&quot;_blank&quot;&gt;rank of an elliptic curve&lt;/a&gt; over a number field (or over ${\mathbb Q}$) turns out to be a hard problem. We need to locate rational points of infinite order, and to figure out the maximum number of such points that are ${\mathbb Z}$-linearly independent. After more than a century of study, there is still no general method for doing this.&lt;/p&gt;

&lt;p&gt;Nonetheless, we can compute many examples using special and ad hoc methods. I’ll talk about a database of these in a moment.&lt;/p&gt;

&lt;p&gt;Based on a careful study of examples, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Birch_and_Swinnerton-Dyer_conjecture&quot; target=&quot;_blank&quot;&gt;Birch-Swinnerton-Dyer Conjecture&lt;/a&gt; (of Millennium Prize fame) suggests that the rank depends on the relationship of an elliptic curve with the &lt;em&gt;prime numbers&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reduction modulo prime numbers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given any curve over ${\mathbb Q}$, we can reduce its equation modulo successive primes $p = 2,3,5,\ldots$ For example, modulo $p = 2$ the equation I wrote down above becomes
\[
y^2 + xy + y = x^3 + x^2.
\]
Over the finite field ${\mathbb F}_2 = {\mathbb Z}/2$, we can count exactly 4 solutions of this curve (including the point at infinity on the $y$-axis). So the group of points over this field has order 
\[
|E({\mathbb F}_2)| = 4.
\]
Unlike the rank of the curve over ${\mathbb Q}$, &lt;a href=&quot;https://en.wikipedia.org/wiki/Counting_points_on_elliptic_curves&quot; target=&quot;_blank&quot;&gt;counting the points of an elliptic curve over the prime fields ${\mathbb F}_p$&lt;/a&gt; is easy. For small primes we can just enumerate the solutions as in this example. For larger primes there is an algorithm with complexity $O(p^\frac{1}{4})$.&lt;/p&gt;

&lt;p&gt;The key to this counting algorithm (which you can read about in the Wikipedia article) is &lt;em&gt;Hasse’s Theorem&lt;/em&gt;, which says that 
\[
p+1 - 2\sqrt{p} \leq |E({\mathbb F}_p)| \leq p+1 + 2\sqrt{p}.
\]
So in other words, the number of points $|E({\mathbb F}_p)|$ is ‘close’ to $p$.&lt;/p&gt;

&lt;p&gt;It is these counts that are used in the Birch-Swinnerton-Dyer conjecture. I won’t talk about that in this post - though I will make use of the sequence of ‘discrepancies’
\[
a_p = p + 1 - |E({\mathbb F}_p)|
\qquad
p = 2,3,5,7,\ldots
\]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The LMFDB database&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With all that as context, where is the data science application?&lt;/p&gt;

&lt;p&gt;The authors of [1], followed by those of [2], asked the question: given a large database of elliptic curves of known rank, can one use the methods of machine learning to model the rank directly as a function of the point counts over prime fields?&lt;/p&gt;

&lt;p&gt;Incidentally, most known elliptic curves over ${\mathbb Q}$ have rank 0 or 1, with curves of higher rank being much rarer. Could a machine learning model recognise higher rank curves from easily computable features (e.g. the count discrepancies $a_p$)? And could we use it to guide mathematical understanding, perhaps to help prove the Birch-Swinnerton-Dyer conjecture or to generate new insights on the rank?&lt;/p&gt;

&lt;p&gt;The data source used in this research is the database &lt;a href=&quot;https://www.lmfdb.org&quot; target=&quot;_blank&quot;&gt;LMFDB&lt;/a&gt; [3].
This database contains, among other things, around 3.8 million elliptic curves over ${\mathbb Q}$ of known rank up to 5. They are organised by &lt;em&gt;conductor&lt;/em&gt; - this is a number whose factorisation encodes primes under which a curve has bad reduction.&lt;/p&gt;

&lt;p&gt;In my experiments, I’ve tried to reproduce most of the results of [1]. I’ve used 59,573 elliptic curves (up to isogeny) of rank 0 ,1 or 2 and conductor in the range 1,000-10,000. This is comparable to the experiments in [1] that I’ll talk about, though that paper also does some work with curves of higher conductor which I will ignore.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Murmurations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The paper [1] makes a remarkable observation.&lt;/p&gt;

&lt;p&gt;As a preamble, suppose the starting question is &lt;em&gt;‘can the sequences of $a_p$ counts discriminate curves of different rank?’&lt;/em&gt; If so, then looking directly at examples does not offer much hope:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/ap_counts.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This plot takes a random curve and shows the sequence $(a_p)$ for the first 1,000 primes. We see that $a_p$ takes values within a range that grows as $O(\sqrt{p})$ in accordance with Hasse’s Theorem. But there is no obvious pattern in the sign of $a_p$, and the picture is indistinguishable to the eye for curves of rank 0,1 or 2.&lt;/p&gt;

&lt;p&gt;However, instead of looking at individual curves, [1] looks at the average of $a_p$ over lots of curves (I’ve taken all those with conductor in the range 5,000-10,000 here). Then we see quite a different picture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/average0-1.png&quot; width=&quot;100%&quot; /&gt;
&lt;img src=&quot;/assets/img/2023-10-27/average0-2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These beautiful patterns are the ‘murmurations’ of the title of [1]. Just to be clear: in these plots, each dot represents not an elliptic curve but a prime number. The key observation in [1] and in these plots is that &lt;em&gt;on average&lt;/em&gt; there is a very clear signal distinguishing curves of different rank.&lt;/p&gt;

&lt;p&gt;(Incidentally, the paper [1] goes on to fit curves to these patterns and tries to understand them. I won’t go there in this post - my interest here is just how to get a predictive model for the rank.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Predicting the rank&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The main claim of [1] is that the rank can reasonably be predicted from a logistic regression model using $(a_p)$ (say for the first 1,000 primes) as feature vector. I have not been able to reproduce this without some further feature engineering (which I suspect is implicit in their work but wasn’t clear to me from the paper).&lt;/p&gt;

&lt;p&gt;The problem is that, as in my first plot above, the sequences $(a_p)$ do not themselves exhibit sufficient discriminatory power for the rank. However, the murmuration plot strongly suggests replacing $(a_p)$ by successive window averages:
\[
b_p = {\rm average}(a_2, a_3, a_5,\dots, a_p)
\]
So I have used as feature vector $(b_p)$ for the first 100 primes. I choose 100 based on the clear separation of ranks we see in the murmuration plots for this range. Then the results are impressive.&lt;/p&gt;

&lt;p&gt;Projecting these 100-dimensional $b$-vectors (for a sample of 30,000 elliptic curves) to the plane using PCA we get some idea of the discriminatory power:
&lt;img src=&quot;/assets/img/2023-10-27/pcaplot.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using t-SNE [4] for a better nonlinear dimensional reduction sharpens the picture (this was the graphic shown at the top of this post):
&lt;img src=&quot;/assets/img/2023-10-27/tsneplot.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What this plot shows is that in the 100-dimensional ($b_p$) feature space we’ve chosen, there are very clean decision boundaries separating the three values of the rank. So it’s then a routine matter to train a classifier.&lt;/p&gt;

&lt;p&gt;As usual, we’ll partition the data into a training set and a test set, balancing the classes within each.
Here are my test results for three models:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Logistic regression using the $a_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_lr_a.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Logistic regression using the $b_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_lr_b.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Neural network with 2 dense hidden layers using the $b_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_mlp_b.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jupyter notebooks containing all the code for these experiments (using &lt;a href=&quot;https://doc.sagemath.org/html/en/reference/arithmetic_curves/index.html&quot; target=&quot;_blank&quot;&gt;SageMath&lt;/a&gt; and &lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot;&gt;TensorFlow&lt;/a&gt;) can be found &lt;a href=&quot;https://github.com/billoxbury/ecrank&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, Alexey Pozdnyakov: &lt;a href=&quot;https://doi.org/10.48550/arXiv.2204.10140&quot; target=&quot;_blank&quot;&gt;Murmurations of elliptic curves&lt;/a&gt;, arXiv.2204.10140 (2022)&lt;/li&gt;
  &lt;li&gt;Matija Kazalicki, Domagoj Vlah: &lt;a href=&quot;https://link.springer.com/article/10.1007/s40993-023-00462-w&quot; target=&quot;_blank&quot;&gt;Ranks of elliptic curves and deep neural networks&lt;/a&gt;, &lt;i&gt;Research in Number Theory&lt;/i&gt; 9:53  (2023) or &lt;a href=&quot;https://arxiv.org/abs/2207.06699&quot; target=&quot;_blank&quot;&gt;arXiv 2207.06699&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The LMFDB Collaboration, &lt;a href=&quot;https://www.lmfdb.org&quot; target=&quot;_blank&quot;&gt;The L-functions and Modular Forms Database&lt;/a&gt; (2023)&lt;/li&gt;
  &lt;li&gt;Laurens van der Maaten, Geoffrey Hinton: &lt;a href=&quot;https://www.cs.toronto.edu/~hinton/absps/tsne.pdf&quot; target=&quot;_blank&quot;&gt;Visualizing Data using t-SNE&lt;/a&gt;, Journal of Machine Learning Research 1 (2008).&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="mathematics" /><summary type="html"></summary></entry><entry><title type="html">Zombie bots and neural bots</title><link href="http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots/" rel="alternate" type="text/html" title="Zombie bots and neural bots" /><published>2023-09-08T00:00:00+00:00</published><updated>2023-09-08T00:00:00+00:00</updated><id>http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots</id><content type="html" xml:base="http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots/">&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/nbot-2.gif&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We all know that neural networks are taking over the world. We see this in the deep learning revolution, in the wonders of deep reinforcement learning and of large language models. These advances combine Big Tech, Big Data and Big Bucks. But the underlying ideas are simple and very powerful, and in this blog I want to share some toy examples that I first played with about 10 years ago.&lt;/p&gt;

&lt;p&gt;I’ll explain the animation above as we go — but basically the moving dot is a bot that’s evolved to seek out and eat red squares, using a brain with just 16 neurons, the output of which are shown, as time progresses, in the blue graph.&lt;/p&gt;

&lt;p&gt;Everything is written in straight C++, with no TensorFlow or other advanced libraries. I’ll talk about the code in another post, but here I just want to focus on the ideas. All training will be by genetic algorithms (as I’ll explain) and not by gradient descent — this immediately simplifies things for us.&lt;/p&gt;

&lt;p&gt;Here’s the task. A bot lives in a 2D binary array, and is to be programmed to efficiently find all the 1s (coloured red in the animations). At each step, the bot can only see 5 immediately adjacent squares (its own, and those to left, right, up and down); each of these can be in one of three states (0,1 or boundary (i.e. non-existent)). And it has 5 actions to choose from: move left, right, up or down, or ‘eat’ the (value of the) current square.&lt;/p&gt;

&lt;p&gt;The first type of program we might think of — let’s call this a zombie bot — consists simply of a 3⁵ = 243-long lookup table of moves, such as:&lt;/p&gt;

&lt;p&gt;304103402202214122102102401303313302201214404102104044203101340202201110102102131401314403344204304401104402441113401241114400300214110441400423443014321343143134201104301204102220314421441333434304333332331233340312101100402201101131422114214&lt;/p&gt;

&lt;p&gt;In other words, for each one of the 3⁵ possible states, just look up the corresponding number from 0 to 4 and take that as the action to follow.&lt;/p&gt;

&lt;p&gt;Challenge: can you design this ‘program’ — i.e. the sequence of digits — to get an optimally efficient bot? (Well, it turns out that optimality is impossible, as we’ll see in a moment.)&lt;/p&gt;

&lt;p&gt;Let’s suppose you’ve done that, and are ready to test your solution against nature’s. So what might nature’s be? Here’s a genetic algorithm approach:&lt;/p&gt;

&lt;p&gt;Let’s call the above lookup table the bot’s genome, and assume that two bots are able to have sex (resulting in two children) by choosing a random partition of their genomes, swapping alternating portions, and then applying some low-probability mutation to each offspring. We then initialise a suitably-sized population, implement sex freely in that population, and retain at each generation only those bots with the best ability to collect 1s (i.e. find red squares). In other words, we’re running a genetic algorithm to optimise a fitness function (which consists of a suitable test regime for hopeful bots).&lt;/p&gt;

&lt;p&gt;OK … so here’s a typical zombie bot after 10 generations of evolution from a random initalisation :grimacing:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-10.gif&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And after 500 generations :worried:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-500.gif&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And after 2000 generations :blush:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-2000.gif&quot; width=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At this point — quite surprisingly — the bot has evolved a ‘reconnaisance’ strategy. You might notice that sometimes when the bot enters a patch of red, it doesn’t start eating immediately, but instead travels to one end of the patch, and then systematically eats its way back across the whole patch. This is clearly a better strategy than to arbitrarily eat in one direction or the other, which would create two islands one of which it cannot easily find its way back to. (Did your hand-crafted program think about this?)&lt;/p&gt;

&lt;p&gt;The zombie bot is therefore well adapted to its task — but it’s not optimal. At the end, it finds itself running round the boundary, unable ever to find its way back to the interior to explore for left-over bits. Since it runs on a fixed lookup table, this is inevitable.&lt;/p&gt;

&lt;p&gt;Now meet the neural bot. This has a genome consisting of 416 real numbers, which are weights of a recurrent neural network with 16 hidden units:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/botnet.png&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the very simplest type of recurrent neural network — and as the diagram suggests, we interpret the input bit vector as defining the current ‘sensory’ state, and the output as defining a ‘motor’ decision.&lt;/p&gt;

&lt;p&gt;(Today, recurrent networks have evolved beyond recognition from this simplest version — from LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Units) to today’s Transformer models. But many of these advances were in response to the challenge of training by gradient descent — for a small task, our example avoids that problem altogether by training with a genetic algorithm.)&lt;/p&gt;

&lt;p&gt;Treating the weights of the network as a ‘genome’, we can now evolve the neural bots in exactly the same way as their zombie counterparts. As we do so, we have at any point in time a population of bots, and we can observe them as individuals. We find that even at this very simple level they demonstrate different ‘personalities’. Here are two examples:&lt;/p&gt;

&lt;p&gt;The first is the one pictured at the top of this post (accompanied by the output of its 16 hidden units at each time step). Take another look.&lt;/p&gt;

&lt;p&gt;This bot is able to move diagonally. That would be impossible for a zombie bot, for which the state uniquely determines the action. And consistent diagonal action requires short-term memory, which is somehow encoded in its 16-bit brain. The bot chooses between diagonal and straight-line travel, in the quest to hoover up red squares.&lt;/p&gt;

&lt;p&gt;The second bot I want to show you is lazier, and has evolved a near-optimal strategy of simply marching up and down, systematically ignoring the bits in the next row it’s coming to. Its laziness (or efficiency) is even visible in its mental state: it clearly has more brain cells than it uses!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/nbot-1.gif&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="artificial_intelligence" /><summary type="html"></summary></entry><entry><title type="html">How to code interactive graphics with R shiny</title><link href="http://localhost:4000/data_science/coding-interactive-graphics/" rel="alternate" type="text/html" title="How to code interactive graphics with R shiny" /><published>2023-03-07T00:00:00+00:00</published><updated>2023-03-07T00:00:00+00:00</updated><id>http://localhost:4000/data_science/coding-interactive-graphics</id><content type="html" xml:base="http://localhost:4000/data_science/coding-interactive-graphics/">&lt;p&gt;&lt;a href=&quot;https://billox.shinyapps.io/zip-topological-viz/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/img/2023-03-07/shiny-app.png&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My earlier blog &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;A Topological Trick for Data Visualisation&lt;/a&gt; described Carlsson’s &lt;i&gt;mapper&lt;/i&gt; construction, that offers a good graph representation of a high-dimensional point cloud. I offered a fancy interactive demo of &lt;i&gt;mapper&lt;/i&gt; on the Zip data set of hand-written digits – shown in the graphic above and linked to it.&lt;/p&gt;

&lt;p&gt;In that blog, I focussed on the mathematical idea behind &lt;i&gt;mapper&lt;/i&gt; and said nothing about how the demo worked. In this blog, I want to say a little bit about the &lt;a href=&quot;https://shiny.rstudio.com/&quot; target=&quot;_blank&quot;&gt;R shiny&lt;/a&gt; code behind the demo, in order to make it a bit more reproducible for interested readers.&lt;/p&gt;

&lt;p&gt;For those already familiar with R, &lt;i&gt;shiny&lt;/i&gt; provides a very easy way to build interactive graphics using the R language. There are lots of good tutorials to be found, so all I’ll say by way of introduction is that a &lt;i&gt;shiny&lt;/i&gt; application is basically defined by two functions &lt;i&gt;shinyUI()&lt;/i&gt; and &lt;i&gt;shinyServer()&lt;/i&gt;, usually saved in their own source files &lt;i&gt;UI.R&lt;/i&gt; and &lt;i&gt;server.R&lt;/i&gt;. A first example to look at is &lt;a href=&quot;https://shiny.rstudio.com/gallery/example-01-hello.html&quot; target=&quot;_blank&quot;&gt;Hello Shiny!&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, with that said, the UI code for the fancy &lt;i&gt;mapper&lt;/i&gt; demo is simply the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shinyUI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fluidPage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titlePanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A topological trick for data visualisation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sidebarLayout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;right&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sidebarPanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sliderInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nbins&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Resolution (nr bins):&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sliderInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;klevel&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Resolution (heirarchical cluster k):&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numericInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;obsvertex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Sample vertex:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plotOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;digitview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mainPanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plotOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;graphview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This says that there’s a side panel with some controls plus a plot output &lt;i&gt;“digitview”&lt;/i&gt;, and a main panel with another plot output &lt;i&gt;“graphview”&lt;/i&gt;. These two plot outputs will be defined in the server file, which we’ll look at in a moment.&lt;/p&gt;

&lt;p&gt;Besides these two outputs, we also see three &lt;i&gt;“input”&lt;/i&gt;s in the sidebarpanel. These define variables (for example &lt;i&gt;input$nbins&lt;/i&gt;) that are picked up from the UI and used by the server function. This repeats the pattern you see in the &lt;a href=&quot;https://shiny.rstudio.com/gallery/example-01-hello.html&quot; target=&quot;_blank&quot;&gt;Hello Shiny!&lt;/a&gt; app.&lt;/p&gt;

&lt;p&gt;So next, the server file:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;helpers.R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# stores some functions needed below&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# the Zip data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shinyServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        
    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# build clusters:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reactive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make.clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nbins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;klevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mg&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reactive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapper.graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    
    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# outputs:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphview&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;renderPlot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show.graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obsvertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;digitview&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;renderPlot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show.digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obsvertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Again, the structure is simple. Starting at the bottom of this code, the two outputs &lt;i&gt;“digitview”&lt;/i&gt; and  &lt;i&gt;“graphview”&lt;/i&gt; are defined. Each of these calls &lt;i&gt;renderPlot()&lt;/i&gt;, which gives a reactive version of some plotting code for passing to the server output that gets picked up by the UI.&lt;/p&gt;

&lt;p&gt;For the two cases, the plotting code is defined by functions &lt;i&gt;show.graph()&lt;/i&gt; and &lt;i&gt;show.digits()&lt;/i&gt; – which I’ve defined in a source file &lt;i&gt;‘helpers.R’&lt;/i&gt;, and I’ll come to in a moment.&lt;/p&gt;

&lt;p&gt;These two functions depend on the data clusters, and the graph structure on these clusters, as I’ve described conceptually in the &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;previous blog&lt;/a&gt;. And they depend on these via the user inputs &lt;i&gt;nbins, klevel, obsvertex&lt;/i&gt;. These variables change in response to the UI controls, so the functions &lt;i&gt;mg(), cluster.set()&lt;/i&gt; are defined to be ‘reactive’ – that is, to link in real time to the input variables.&lt;/p&gt;

&lt;p&gt;At this point you can see that the work of implementing the construction I described in the &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;previous blog&lt;/a&gt; is wrapped up in the functions &lt;i&gt;make.clusters()&lt;/i&gt;, &lt;i&gt;mapper.graph()&lt;/i&gt;, &lt;i&gt;show.graph()&lt;/i&gt; and &lt;i&gt;show.digits()&lt;/i&gt;. I won’t go into all of these in gory detail. The reader should get the idea of the first two from the previous blog.&lt;/p&gt;

&lt;p&gt;But I will say a bit about &lt;i&gt;show.graph()&lt;/i&gt;, as this uses the excellent library &lt;a href=&quot;https://igraph.org/&quot; target=&quot;_blank&quot;&gt;igraph&lt;/a&gt; and the reader may or may not be familiar with this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;show.graph&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# connected components of igraph object g&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# edge parameters&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow.mode&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curved&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex - size by cluster size&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.cex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.cex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex label by most common digit in the cluster&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]];&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex - colour by connected component&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame.color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;membership&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;membership&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# highlight the selected base vertex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orange&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# output igraph plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The function takes inputs a graph &lt;i&gt;g&lt;/i&gt; (an &lt;i&gt;igraph&lt;/i&gt; object), a cluster set (of vertex indices) &lt;i&gt;cset&lt;/i&gt; and a selected vertex &lt;i&gt;v&lt;/i&gt; (set as -1, or ‘none’ by default). It outputs a plot that looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-03-07/zip2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html"></summary></entry><entry><title type="html">Language barriers in global conservation</title><link href="http://localhost:4000/environment/language_barriers/" rel="alternate" type="text/html" title="Language barriers in global conservation" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>http://localhost:4000/environment/language_barriers</id><content type="html" xml:base="http://localhost:4000/environment/language_barriers/">&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-02-22/birdclouds.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Wildlife tends not to respect national boundaries. Birds, in particular, as they migrate across and between continents, ignore not only borders but even the cultures and languages of the scientists who may be trying to study and protect them. And, surprise surprise, not all of the world’s science is written in English.&lt;/p&gt;

&lt;p&gt;According to a recent study [1], more than 30% of scientific articles on biodiversity conservation are written in non-English languages. Moreover, the authors claim that non-English language scientific outputs – at least within biodiversity conservation – are increasing both in volume and in quality. In geographic regions where English is not widely used – as in some of the world’s biodiversity hotspots – key data and evidence are generated by local scientists and even by citizen science projects in local languages. So when it comes to tracking species with global geographic ranges, restricting only to English-language scientific outputs can lead to key gaps in knowledge.&lt;/p&gt;

&lt;p&gt;The study [2] takes a closer look at this issue for bird species. They compare the known geographic ranges of more than 10,000 species with the official languages listed for the countries covered by those ranges. They show that more than 1,500 species have coverage of at least 10 languages. High numbers of ‘multi-lingual’ species have ranges spanning Eastern Europe, Russia and central Asia. Nevertheless, they also observe that four European languages – English, Spanish, Portuguese and French – dominate species coverage globally, each reaching between 3,000 and 6,000 bird species.&lt;/p&gt;

&lt;p&gt;In a project for &lt;a href=&quot;https://www.birdlife.org/&quot; target=&quot;_blank&quot;&gt;BirdLife International&lt;/a&gt;, I have been able to put some of these observations to the test, from the complementary perspective of what can be seen directly in the scientific literature. &lt;i&gt;LitScan&lt;/i&gt; is a system to crawl and identify scientific articles of relevance to Red List assessments. It scans various sources across multiple languages; makes use of &lt;a href=&quot;https://spacy.io/&quot; target=&quot;_blank&quot;&gt;spaCy&lt;/a&gt; for text-processing (including language id, discovery of species mentions and conservation relevance); and uses Cloud cognitive services for translation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-02-22/Picus_viridis.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the purposes of this blog post – and for comparison with the results of [2] – I want to focus on just one of the &lt;i&gt;LitScan&lt;/i&gt; sources &lt;a href=&quot;https://openalex.org/&quot; target=&quot;_blank&quot;&gt;OpenAlex&lt;/a&gt; [3]. This is an extremely useful open-source repository of metadata for scientific documnents drawing on an impressive &lt;a href=&quot;https://openalex.org/about&quot; target=&quot;_blank&quot;&gt;range of sources&lt;/a&gt;. I don’t know what the exact language coverage of OpenAlex is (and I’m sure it could be improved), but I can make some observations based on &lt;i&gt;LitScan&lt;/i&gt;.&lt;/p&gt;

&lt;p&gt;(Incidentally, besides OpenAlex, &lt;i&gt;LitScan&lt;/i&gt; taps directly into various non-English sources. These are quite specific and would bias any comparison with [2], so in this post I’ll just restrict to &lt;i&gt;LitScan&lt;/i&gt; data that comes from OpenAlex.)&lt;/p&gt;

&lt;p&gt;So here’s a data set – used by &lt;i&gt;LitScan&lt;/i&gt; but constructed as follows. Over a 3-month period a daily request was made to OpenAlex. The request consisted of 500 searches, each on the scientific name of a bird species drawn at random from a list of 11,188. The searches are not all successful, and over the collection period the number of documents returned – after some additional filtering for conservation relevance and publication since the year 2000 – was 35,303 (so averaging about 400 per day).&lt;/p&gt;

&lt;p&gt;The total number of species covered by these documents was 3,517, in a total of 32 languages – by far dominated by English (32,239 documents), with the next most numerous language being Spanish (824 documents).&lt;/p&gt;

&lt;p&gt;We can now ask, in the spirit of [2]: &lt;b&gt;how many species&lt;/b&gt; are found in &lt;b&gt;non-English documents only&lt;/b&gt;? Moreover, since we are interested in conservation relevance, we can ask for this number broken down by red-list status – as defined by the &lt;a href=&quot;https://www.iucnredlist.org/&quot; target=&quot;_blank&quot;&gt;IUCN Red List of Threatened Species&lt;/a&gt; – as well as language:&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&quot;text-align:left;&quot;&gt;   &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; LC &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; NT &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; VU &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; EN &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; CR &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; EX &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Spanish &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 211 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 13 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 14 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Portuguese &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 52 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 11 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 7 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 5 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Indonesian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 29 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 11 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; French &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 25 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 8 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 3 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; German &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 5 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Korean &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 4 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Mandarin &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Czech &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Catalan &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Norwegian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Croatian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(The columns are the red-list categories &lt;i&gt;Least Concern&lt;/i&gt;, &lt;i&gt;Near Threatened&lt;/i&gt;, &lt;i&gt;VUlnerable&lt;/i&gt;, &lt;i&gt;ENdangered&lt;/i&gt;, &lt;i&gt;CRitically endangered&lt;/i&gt; and &lt;i&gt;EXtinct&lt;/i&gt;.)&lt;/p&gt;

&lt;p&gt;These are small numbers, but every species counted in this table represents information that may be lost to red-list assessors who have access only to English-language science. Moreover, many more species are represented in both English and non-English documents (and so are not counted here).&lt;/p&gt;

&lt;p&gt;The document sampling using OpenAlex is far from unbiased – clearly we have not tapped into a much wider literature in, say, Mandarin or Korean. The &lt;i&gt;LitScan&lt;/i&gt; ambition is to maximise the use of sources in those languages directly in the future. Nevertheless, the analysis offers an interesting corroboration of the observations in [1,2].&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;T. Amano et al: &lt;a href=&quot;https://doi.org/10.1371/journal.pbio.3001296&quot; target=&quot;_blank&quot;&gt;Tapping into non-English language science for conservation of global biodiversity&lt;/a&gt;, PLOS Biology (2021) &lt;i&gt;doi: 10.1371/journal.pbio.3001296&lt;/i&gt;&lt;/li&gt;
  &lt;li&gt;Pablo Jose Negret, Scott C. Atkinson, Bradley K. Woodworth, Marina Corella Tor, James R. Allan, Richard A. Fuller, Tatsuya Amano: &lt;a href=&quot;https://doi.org/10.1371/journal.pone.0267151&quot; target=&quot;_blank&quot;&gt;Language barriers in global bird conservation&lt;/a&gt; PLOS One (2022) &lt;i&gt;doi: 10.1371/journal.pone.0267151&lt;/i&gt;&lt;/li&gt;
  &lt;li&gt;Priem, J., Piwowar, H., &amp;amp; Orr, R. (2022). &lt;a href=&quot;https://openalex.org/&quot; target=&quot;_blank&quot;&gt;OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts&lt;/a&gt; (2022) &lt;i&gt;arXiv: &lt;a href=&quot;https://arxiv.org/abs/2205.01833&quot; target=&quot;_blank&quot;&gt;arxiv.org/abs/2205.01833&lt;/a&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">Navigating the PLOS ONE topic tree</title><link href="http://localhost:4000/data_science/plosone-topic-tree/" rel="alternate" type="text/html" title="Navigating the PLOS ONE topic tree" /><published>2022-02-10T00:00:00+00:00</published><updated>2022-02-10T00:00:00+00:00</updated><id>http://localhost:4000/data_science/plosone-topic-tree</id><content type="html" xml:base="http://localhost:4000/data_science/plosone-topic-tree/">&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/browse_topics.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PLOS ONE is a respected multidisciplinary journal publishing research from&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;over two hundred subject areas across science, engineering, medicine, and the related social sciences and humanities.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But exactly &lt;strong&gt;how many&lt;/strong&gt; subject areas?&lt;/p&gt;

&lt;p&gt;At the top level (as shown in the screenshot above), these subject areas fall under eleven headings from &lt;em&gt;Biology and life sciences&lt;/em&gt; to &lt;em&gt;Social sciences&lt;/em&gt;. For each of these headings – such as &lt;em&gt;Computer and information sciences&lt;/em&gt; below - we are told the number of articles (in this case 32,397) and can browse further subheadings:&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2022-02-10/compsci_count.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2022-02-10/compsci_topics.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p&gt;This post is about a short exercise to scan the entire tree of PLOS ONE topics, asking:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;how does one extract and represent this tree?&lt;/li&gt;
  &lt;li&gt;are the article counts per topic &lt;em&gt;consistent&lt;/em&gt; e.g. in the sense that each count is the sum of the counts at the leaves of the corresponding subtree?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Visually, the result of the analysis is plots such as the following (the topic trees of some of the top-level headings):&lt;/p&gt;

&lt;embed src=&quot;/assets/img/2022-02-10/seven_trees.pdf&quot; type=&quot;application/pdf&quot; frameborder=&quot;0&quot; scrolling=&quot;auto&quot; height=&quot;100%&quot; width=&quot;100%&quot; /&gt;

&lt;h2&gt;1. Crawling&lt;/h2&gt;

&lt;p&gt;The starting task was to crawl the PLOS ONE pages. To do this, we initialise a data frame with a single row (I’ll use Python-like pseudocode throughout - most of this exercise was actually done in R):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;node&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;s&quot;&gt;&apos;parent&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;s&quot;&gt;&apos;parent_topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;… and then add tree nodes to the data frame via the following breadth-first search:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;browse_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://journals.plos.org/plosone/browse/&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browse_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# read HTML
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;next_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# read HTML    
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;node&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;parent&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                          &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;parent_topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
                          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this code, the functions &lt;tt&gt;find_count()&lt;/tt&gt; and &lt;tt&gt;find_children()&lt;/tt&gt; parse the HTML of the currently visited topic page and extract the count and subtopics respectively. (For this I use the package &lt;em&gt;rvest&lt;/em&gt; in R.)&lt;/p&gt;

&lt;h2&gt;2. Counting&lt;/h2&gt;

&lt;p&gt;The code generates a data frame with &lt;i&gt;(as of 9 Feb 2022)&lt;/i&gt; a total of 16,721 rows (topics). From this data frame we can read off any tree statistics - for example the node count by depth in the tree:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/count_by_depth.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To illustrate the data frame, the following slice is the part of the tree below node 49, &lt;i&gt;sports_science&lt;/i&gt;. (This is an example of a &lt;em&gt;clade&lt;/em&gt;: a subtree that exactly consists of one node and all its descendants:)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/sports_tree0.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/sports_tree1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first thing to note is that the article counts (as read off from the PLOS ONE topic pages) are not in any sense consistent! (That was question 2 at the top of this post.)&lt;/p&gt;

&lt;p&gt;At each node, we can read off an &lt;strong&gt;excess count&lt;/strong&gt;, which is the difference between the advertised article count and the sum of the counts at child nodes. This excess is usually positive: for example, at the topic &lt;em&gt;exercise&lt;/em&gt; the excess is 1,515 - the number of articles that presumably do not fall under the subtopics of &lt;i&gt;aerobic_exercise&lt;/i&gt; or &lt;i&gt;strength_training&lt;/i&gt;. This is to be expected if the topic tree grows over time with new subtopics being added to the &lt;a href=&quot;https://github.com/PLOS/plos-thesaurus&quot; target=&quot;_blank&quot;&gt;PLOS thesaurus&lt;/a&gt;. On the other hand, the excess count is often negative. For example, the count at &lt;i&gt;sports_science&lt;/i&gt; is actually &lt;em&gt;less than&lt;/em&gt; the counts at its two subtopics &lt;i&gt;sports&lt;/i&gt; and &lt;i&gt;sports_and_exercise_medicine&lt;/i&gt;. At some point, the parent node has stopped counting!&lt;/p&gt;

&lt;p&gt;(It turns out that the excess count has a large negative value at all of the 11 top-level topics – which are therefore underestimating the number of articles they cover.)&lt;/p&gt;

&lt;h2&gt;3. Drawing&lt;/h2&gt;

&lt;p&gt;Finally, a word about tree formats and visualisation. The circular plots shown above could have been made using a package like R &lt;em&gt;phylotools&lt;/em&gt;. In fact, I took a shortcut and used the very convenient &lt;a href=&quot;https://itol.embl.de/&quot; target=&quot;_blank&quot;&gt;Interactive Tree Of Life (iTOL)&lt;/a&gt; site.&lt;/p&gt;

&lt;p&gt;In either case, a more compact data format is needed than the data frame shown above. A popular format that I used is the &lt;strong&gt;Newick format&lt;/strong&gt;. The idea of Newick format is that the tree is represented by a string with the recursive form&lt;/p&gt;

&lt;p&gt;\[
\nu({\rm tree}) = (\nu({\rm child}_1),\ldots,\nu({\rm child}_k))\nu({\rm root})
\]&lt;/p&gt;

&lt;p&gt;and where $\nu({\rm single\ node})$ is any convenient string representing that node, e.g. the topic name. Converting from the data frame shown above to Newick format is then achieved with a simple recursive function:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;(&quot;&lt;/span&gt;                           &lt;span class=&quot;c1&quot;&gt;# open bracket
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# insert commas-separated child strings
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;,&apos;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;,&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# remove final comma
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;)&apos;&lt;/span&gt;                          &lt;span class=&quot;c1&quot;&gt;# close bracket
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;               &lt;span class=&quot;c1&quot;&gt;# append parent string
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Applied to the little &lt;i&gt;sports_science&lt;/i&gt; data frame this outputs:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&apos;(sports,((aerobic_exercise,strength_training)exercise)sports_and_exercise_medicine)sports_science&apos;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html"></summary></entry><entry><title type="html">COP26: seeing the wood for the trees</title><link href="http://localhost:4000/environment/cop26-nzs/" rel="alternate" type="text/html" title="COP26: seeing the wood for the trees" /><published>2021-11-03T00:00:00+00:00</published><updated>2021-11-03T00:00:00+00:00</updated><id>http://localhost:4000/environment/cop26-nzs</id><content type="html" xml:base="http://localhost:4000/environment/cop26-nzs/">&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-03/woodfortrees1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The climate crisis poses an almost overwhelming challenge to humanity, and it is very easy to be pessimistic. But there are also some reasons to be hopeful. Many will have been inspired by Prince William’s Earthshot initiative, by the vision behind it and the passion and creativity of the finalists and other innovators. It gives me genuine hope that we have the capacity to correct our course for a safe future.&lt;/p&gt;

&lt;p&gt;You will hear about many innovations and tech solutions for sustainability in the margins of COP26. However, the success of the conference will stand or fall on one thing only: the ability of the international community to agree a practical pathway to achieve the 1.5°C goal of the Paris agreement.&lt;/p&gt;

&lt;p&gt;This is ultimately a numbers game. One of the most hopeful conclusions from the 
&lt;a href=&quot;https://www.ipcc.ch/report/ar6/wg1/#FullReport&quot;&gt;2021 IPCC 6th Assessment Report&lt;/a&gt;
 is that there is a strong linear relationship between the average global temperature we arrive at this century and the total volume of carbon that we emit into the atmosphere from today. In other words, the world has an emissions ‘budget’: the lower the budget, the lower the final temperature rise.&lt;/p&gt;

&lt;p&gt;To understand the budget choices, the following table is from the IPCC report:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-03/image1.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The table expresses uncertainties and margins of error. Sorry. But it’s the best science we have to go on, so let’s see what it says.&lt;/p&gt;

&lt;p&gt;The rows of the table express budgets (in GtCO2, or giga-tonnes of CO2 emission) for limiting the global temperature rise to values on the left-hand margin, with likelihood expressed in the top margin. So, for example, 500 GtCO2 buys a 50% chance of staying within 1.5°C in this century. Let’s go with that for the moment – assuming a 50% chance feels a safe enough bet for you.&lt;/p&gt;

&lt;p&gt;So how much is 500 GtCO2? For comparison, the world in 2020 released approximately 40 GtCO2 (with the UK responsible for about 0.3 GtCO2 of that). So at current rates, 500 equates to about 12 years. Or if we could assume a 7% worldwide reduction in emissions every year, then it buys us 30 years.&lt;/p&gt;

&lt;p&gt;(Two more comparisons: the proposed coking coal mine at Woodhouse Colliery would commit the UK to about 0.16 GtCO2 from the coal extracted over the lifetime of the mine; the Cambo oil field in the North Sea commits us to about 0.3 GtCO2. Both would eat significantly into any reasonable budget for the UK.)&lt;/p&gt;

&lt;p&gt;This is the numbers game that COP26 has to solve in order to ensure a safe future. What emissions budget can the international community agree that will set an acceptable level of temperature risk? Given that budget, how will it be divided equitably among nations? And how do we support poorer nations to live within their budget as they transition to a zero-carbon future?&lt;/p&gt;

&lt;p&gt;All too often, responding to the climate crisis is framed as being about personal choices (you should fly less, you should eat less meat). It isn’t. Ultimately, it depends on science-driven policies, tireless diplomacy and international cooperation to shift those big carbon numbers. COP26 is a critical part of that process.&lt;/p&gt;

&lt;p&gt;Yes, our lifestyles will change, and individual choices are important – but for the majority they’ll change the way they always have done: in response to better choices coming along through vision, investment and legislation.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">COP26: why 1.5 degrees?</title><link href="http://localhost:4000/environment/cop26-why1pt5/" rel="alternate" type="text/html" title="COP26: why 1.5 degrees?" /><published>2021-11-02T00:00:00+00:00</published><updated>2021-11-02T00:00:00+00:00</updated><id>http://localhost:4000/environment/cop26-why1pt5</id><content type="html" xml:base="http://localhost:4000/environment/cop26-why1pt5/">&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image1.jpeg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the 2015 Paris Agreement, countries of the world signed up to &lt;em&gt;“keep the rise in average global temperature to well below 2°C above pre-industrial levels, and preferably limit the increase to 1.5°C”&lt;/em&gt;.  This month’s COP26 summit is the last best chance for nations to agree plans of action to achieve that goal. For the reasons I discussed in the previous blog, it’s vital for all our futures that we succeed.&lt;/p&gt;

&lt;p&gt;So why 1.5°C? The figure sounds insignificant – what does it mean?&lt;/p&gt;

&lt;p&gt;Global average temperature is not a flat, uniform thing. It’s more like the surface of the sea – it has peaks and troughs. And actually, as the average rises, so does the variation between those peaks and troughs. The graphic above, taken from the &lt;a href=&quot;https://www.atlasoftheinvisible.com/&quot;&gt;Atlas of the Invisible&lt;/a&gt;, illustrates this. Each square is a little map of the Earth, showing average temperature from 1890 to 2019. The colour, from blue to red, shows how far the temperature is below or above the global average for the ‘baseline period’ (1960s to 1980s). What you see is not only the trend but the variation across the planet.&lt;/p&gt;

&lt;p&gt;So a total average temperature rise of 1.1°C (above the pre-industrial average, which is roughly where we are today), affects different parts of the planet in different ways, and has led to the big effects in terms of extreme weather, melting ice and changing rainfall patterns that we see today.&lt;/p&gt;

&lt;p&gt;Let’s put that figure of 1.1°C in historical context. The following graphic is taken from the &lt;a href=&quot;https://www.ipcc.ch/report/ar6/wg1/#FullReport&quot;&gt;IPCC’s 6th Assessment Report&lt;/a&gt; this summer. It shows that insignificant-looking temperature difference in the context of the last two thousand years. In this context, we see that 1.1°C is a very big deal and that the rise is not gradual but is better thought of as a shock to the system.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The graphic also shows that today’s temperature is outside anything the planet has experienced in the past 100,000 years. At 1.5°C we will already head beyond any conditions that have existed during the lifetime of our species. Yet the IPCC report makes clear that we are very likely to exceed 1.5°C by 2040 and possibly by 2030. Without radical actions agreed at COP26, according to the IPCC, we are heading past 2.4°C by 2040 and to around 4.0°C by the end of the century.&lt;/p&gt;

&lt;p&gt;A temperature rise of 4.0°C is pretty unthinkable. In geological time it takes us back nearly 50 million years to an age before primates had evolved and when the poles were temperate. The sea level rise this would induce would drown all the major coastal cities in the world.&lt;/p&gt;

&lt;p&gt;A major risk of permitting uncontrolled temperature rise is the existence of tipping points in the Earth system – temperature levels at which global processes will kick in that would send the temperature rise higher still. The graphic below, by Tim Lenton, illustrates these tipping points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image3.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So the threats are real and current climate change is very much a crisis. But it is still not too late in the day, and there is no doubt that humanity has the ingenuity and resourcefulness to rise to the challenge. Rising to the challenge is just what we have to look to COP26 to do.&lt;/p&gt;

&lt;p&gt;The problem to be solved is stated as a number, 1.5 degrees – so any solutions have to play a numbers game. I’ll talk about that in the last blog.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry></feed>