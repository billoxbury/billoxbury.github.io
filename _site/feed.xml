<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-10-30T07:14:43+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Bills.Data</title><subtitle>Exploring ideas in data science</subtitle><author><name>Bill Oxbury</name></author><entry><title type="html">Predicting the rank of an elliptic curve</title><link href="http://localhost:4000/mathematics/predicting-elliptic-curve-rank/" rel="alternate" type="text/html" title="Predicting the rank of an elliptic curve" /><published>2023-10-27T00:00:00+00:00</published><updated>2023-10-27T00:00:00+00:00</updated><id>http://localhost:4000/mathematics/predicting-elliptic-curve-rank</id><content type="html" xml:base="http://localhost:4000/mathematics/predicting-elliptic-curve-rank/">&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/tsne.png&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of all the hype that attaches to machine learning these days, among the least trumpeted applications - but to my mind some of the most interesting - are those applications of machine learning to mathematics itself. In this post I want to talk about an application demonstrated in the paper [1] &lt;a href=&quot;https://doi.org/10.48550/arXiv.2204.10140&quot; target=&quot;_blank&quot;&gt;Murmurations of elliptic curves&lt;/a&gt;. I will discuss some experiments reproducing the results of that paper.&lt;/p&gt;

&lt;p&gt;Spoiler for the graphic above: each dot represents an elliptic curve over ${\mathbb Q}$ coloured by the rank of the curve; its position in the plane depending only on the numbers of points on the curve modulo the first 100 prime numbers. (I’ll explain all this as we go!)&lt;/p&gt;

&lt;p&gt;The subject requires quite a bit of background, but it’s a story worth telling: it relates closely to a problem, the &lt;em&gt;Birch-Swinnerton-Dyer Conjecture&lt;/em&gt;, which is one of the seven $1,000,000 &lt;a href=&quot;https://en.wikipedia.org/wiki/Millennium_Prize_Problems&quot; target=&quot;_blank&quot;&gt;Millennium Prize Problems&lt;/a&gt; announced by the Clay Mathematics Institute in 2000.&lt;/p&gt;

&lt;p&gt;Let’s start with:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is an elliptic curve?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;An &lt;a href=&quot;https://en.wikipedia.org/wiki/Elliptic_curve&quot; target=&quot;_blank&quot;&gt;elliptic curve&lt;/a&gt; is essentially a plane curve defined by a cubic equation in coordinates $x,y$, for example
\[
y^2 + xy + y = x^3 - x^2 - 9916x - 377564.
\]
The coefficients can be any real or complex numbers, but in this post I’m only concerned with curves with coefficients in the rational numbers ${\mathbb Q}$, as in this example. These are called elliptic curves over ${\mathbb Q}$.&lt;/p&gt;

&lt;p&gt;Elliptic curves have both a long mathematical history and a surprising modern relevance - both on account of the fact that points on the curve naturally form a &lt;em&gt;group&lt;/em&gt;, via the rule that three points are collinear in the plane if and only if they add to zero in the group law:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/grouplaw.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(The identity element $O_E$ is usually taken to be the point at infinity on the $y$-axis.)&lt;/p&gt;

&lt;p&gt;The modern relevance of this is the use of elliptic curve groups in &lt;a href=&quot;https://en.wikipedia.org/wiki/Elliptic_Curve_Digital_Signature_Algorithm&quot; target=&quot;_blank&quot;&gt;digital security&lt;/a&gt;. The mathematical relevance is in understanding the structure of this group for any given curve. (And, of course, the mathematical theory is critical for the secure use of elliptic curves in encryption and signature schemes.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the rank?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The rational points on an elliptic curve $E$, which we denote by $E({\mathbb Q})$, form an &lt;em&gt;abelian group&lt;/em&gt; - that is, the group is commutative $P + Q = Q + P$. Moreover, the &lt;em&gt;Mordell-Weil Theorem&lt;/em&gt;, proved in the 1920s, says that this group is &lt;em&gt;finitely generated&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;(Notice that I’ve specified points in the rational field ${\mathbb Q}$. If I’d said points in the complex field ${\mathbb C}$, the theorem would not be true - in fact the group $E({\mathbb C})$ is isomorphic to a &lt;em&gt;torus group&lt;/em&gt; $S^1 \times S^1$. So the field matters! Most of what I’ll say below is true for any &lt;em&gt;algebraic number field&lt;/em&gt; - but I want to keep things simple and only talk about curves over ${\mathbb Q}$.)&lt;/p&gt;

&lt;p&gt;So $E({\mathbb Q})$ is a finitely generated abelian group. This means that the group must be isomorphic to&lt;/p&gt;

&lt;p&gt;\[
{\mathbb Z}^r \oplus E({\mathbb Q})_{\rm torsion}
\]&lt;/p&gt;

&lt;p&gt;where the torsion part is a finite group and the number $r$ is called the &lt;em&gt;rank&lt;/em&gt; of the group.&lt;/p&gt;

&lt;p&gt;Computing the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rank_of_an_elliptic_curve&quot; target=&quot;_blank&quot;&gt;rank of an elliptic curve&lt;/a&gt; over a number field (or over ${\mathbb Q}$) turns out to be a hard problem. We need to locate rational points of infinite order, and to figure out the maximum number of such points that are ${\mathbb Z}$-linearly independent. After more than a century of study, there is still no general method for doing this.&lt;/p&gt;

&lt;p&gt;Nonetheless, we can compute many examples using special and ad hoc methods. I’ll talk about a database of these in a moment.&lt;/p&gt;

&lt;p&gt;Based on a careful study of examples, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Birch_and_Swinnerton-Dyer_conjecture&quot; target=&quot;_blank&quot;&gt;Birch-Swinnerton-Dyer Conjecture&lt;/a&gt; (of Millennium Prize fame) suggests that the rank depends on the relationship of an elliptic curve with the &lt;em&gt;prime numbers&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reduction modulo prime numbers&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given any curve over ${\mathbb Q}$, we can reduce its equation modulo successive primes $p = 2,3,5,\ldots$ For example, modulo $p = 2$ the equation I wrote down above becomes
\[
y^2 + xy + y = x^3 + x^2.
\]
Over the finite field ${\mathbb F}_2 = {\mathbb Z}/2$, we can count exactly 4 solutions of this curve (including the point at infinity on the $y$-axis). So the group of points over this field has order 
\[
|E({\mathbb F}_2)| = 4.
\]
Unlike the rank of the curve over ${\mathbb Q}$, &lt;a href=&quot;https://en.wikipedia.org/wiki/Counting_points_on_elliptic_curves&quot; target=&quot;_blank&quot;&gt;counting the points of an elliptic curve over the prime fields ${\mathbb F}_p$&lt;/a&gt; is easy. For small primes we can just enumerate the solutions as in this example. For larger primes there is an algorithm with complexity $O(p^\frac{1}{4})$.&lt;/p&gt;

&lt;p&gt;The key to this counting algorithm (which you can read about in the Wikipedia article) is &lt;em&gt;Hasse’s Theorem&lt;/em&gt;, which says that 
\[
p+1 - 2\sqrt{p} \leq |E({\mathbb F}_p)| \leq p+1 + 2\sqrt{p}.
\]
So in other words, the number of points $|E({\mathbb F}_p)|$ is ‘close’ to $p$.&lt;/p&gt;

&lt;p&gt;It is these counts that are used in the Birch-Swinnerton-Dyer conjecture. I won’t talk about that in this post - though I will make use of the sequence of ‘discrepancies’
\[
a_p = p + 1 - |E({\mathbb F}_p)|
\qquad
p = 2,3,5,7,\ldots
\]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The LMFDB database&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With all that as context, where is the data science application?&lt;/p&gt;

&lt;p&gt;The authors of [1], followed by those of [2], asked the question: given a large database of elliptic curves of known rank, can one use the methods of machine learning to model the rank directly as a function of the point counts over prime fields?&lt;/p&gt;

&lt;p&gt;Incidentally, most known elliptic curves over ${\mathbb Q}$ have rank 0 or 1, with curves of higher rank being much rarer. Could a machine learning model recognise higher rank curves from easily computable features (e.g. the count discrepancies $a_p$)? And could we use it to guide mathematical understanding, perhaps to help prove the Birch-Swinnerton-Dyer conjecture or to generate new insights on the rank?&lt;/p&gt;

&lt;p&gt;The data source used in this research is the database &lt;a href=&quot;https://www.lmfdb.org&quot; target=&quot;_blank&quot;&gt;LMFDB&lt;/a&gt; [3].
This database contains, among other things, around 3.8 million elliptic curves over ${\mathbb Q}$ of known rank up to 5. They are organised by &lt;em&gt;conductor&lt;/em&gt; - this is a number whose factorisation encodes primes under which a curve has bad reduction.&lt;/p&gt;

&lt;p&gt;In my experiments, I’ve tried to reproduce most of the results of [1]. I’ve used 59,573 elliptic curves (up to isogeny) of rank 0 ,1 or 2 and conductor in the range 1,000-10,000. This is comparable to the experiments in [1] that I’ll talk about, though that paper also does some work with curves of higher conductor which I will ignore.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Murmurations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The paper [1] makes a remarkable observation.&lt;/p&gt;

&lt;p&gt;As a preamble, suppose the starting question is &lt;em&gt;‘can the sequences of $a_p$ counts discriminate curves of different rank?’&lt;/em&gt; If so, then looking directly at examples does not offer much hope:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/ap_counts.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This plot takes a random curve and shows the sequence $(a_p)$ for the first 1,000 primes. We see that $a_p$ takes values within a range that grows as $O(\sqrt{p})$ in accordance with Hasse’s Theorem. But there is no obvious pattern in the sign of $a_p$, and the picture is indistinguishable to the eye for curves of rank 0,1 or 2.&lt;/p&gt;

&lt;p&gt;However, instead of looking at individual curves, [1] looks at the average of $a_p$ over lots of curves (I’ve taken all those with conductor in the range 5,000-10,000 here). Then we see quite a different picture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-10-27/average0-1.png&quot; width=&quot;100%&quot; /&gt;
&lt;img src=&quot;/assets/img/2023-10-27/average0-2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These beautiful patterns are the ‘murmurations’ of the title of [1]. Just to be clear: in these plots, each dot represents not an elliptic curve but a prime number. The key observation in [1] and in these plots is that &lt;em&gt;on average&lt;/em&gt; there is a very clear signal distinguishing curves of different rank.&lt;/p&gt;

&lt;p&gt;(Incidentally, the paper [1] goes on to fit curves to these patterns and tries to understand them. I won’t go there in this post - my interest here is just how to get a predictive model for the rank.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Predicting the rank&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The main claim of [1] is that the rank can reasonably be predicted from a logistic regression model using $(a_p)$ (say for the first 1,000 primes) as feature vector. I have not been able to reproduce this without some further feature engineering (which I suspect is implicit in their work but wasn’t clear to me from the paper).&lt;/p&gt;

&lt;p&gt;The problem is that, as in my first plot above, the sequences $(a_p)$ do not themselves exhibit sufficient discriminatory power for the rank. However, the murmuration plot strongly suggests replacing $(a_p)$ by successive window averages:
\[
b_p = {\rm average}(a_2, a_3, a_5,\dots, a_p)
\]
So I have used as feature vector $(b_p)$ for the first 100 primes. I choose 100 based on the clear separation of ranks we see in the murmuration plots for this range. Then the results are impressive.&lt;/p&gt;

&lt;p&gt;Projecting these 100-dimensional $b$-vectors (for a sample of 30,000 elliptic curves) to the plane using PCA we get some idea of the discriminatory power:
&lt;img src=&quot;/assets/img/2023-10-27/pcaplot.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using t-SNE [4] for a better nonlinear dimensional reduction sharpens the picture (this was the graphic shown at the top of this post):
&lt;img src=&quot;/assets/img/2023-10-27/tsneplot.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What this plot shows is that in the 100-dimensional ($b_p$) feature space we’ve chosen, there are very clean decision buondaries separating the three values of the rank. So it’s then a routine matter to train a classifier.&lt;/p&gt;

&lt;p&gt;As usual, we’ll partition the data into a training set and a test set, balancing the classes within each.
Here are the test results for three models:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Logistic regression using the $a_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_lr_a.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Logistic regression using the $b_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_lr_b.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Neural network with 2 dense hidden layers using the $b_p$ features:&lt;/em&gt;
&lt;img src=&quot;/assets/img/2023-10-27/model_mlp_b.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jupyter notebooks containing all the code for these experiments (using &lt;a href=&quot;https://doc.sagemath.org/html/en/reference/arithmetic_curves/index.html&quot; target=&quot;_blank&quot;&gt;SageMath&lt;/a&gt; and &lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot;&gt;TensorFlow&lt;/a&gt;) can be found &lt;a href=&quot;https://github.com/billoxbury/ecrank&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, Alexey Pozdnyakov: &lt;a href=&quot;https://doi.org/10.48550/arXiv.2204.10140&quot; target=&quot;_blank&quot;&gt;Murmurations of elliptic curves&lt;/a&gt;, arXiv.2204.10140 (2022)&lt;/li&gt;
  &lt;li&gt;Matija Kazalicki, Domagoj Vlah: &lt;a href=&quot;https://link.springer.com/article/10.1007/s40993-023-00462-w&quot; target=&quot;_blank&quot;&gt;Ranks of elliptic curves and deep neural networks&lt;/a&gt;, &lt;i&gt;Research in Number Theory&lt;/i&gt; 9:53  (2023) or &lt;a href=&quot;https://arxiv.org/abs/2207.06699&quot; target=&quot;_blank&quot;&gt;arXiv 2207.06699&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;The LMFDB Collaboration, &lt;a href=&quot;https://www.lmfdb.org&quot; target=&quot;_blank&quot;&gt;The L-functions and Modular Forms Database&lt;/a&gt; (2023)&lt;/li&gt;
  &lt;li&gt;Laurens van der Maaten, Geoffrey Hinton: &lt;a href=&quot;https://www.cs.toronto.edu/~hinton/absps/tsne.pdf&quot; target=&quot;_blank&quot;&gt;Visualizing Data using t-SNE&lt;/a&gt;, Journal of Machine Learning Research 1 (2008).&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="mathematics" /><summary type="html"></summary></entry><entry><title type="html">Zombie bots and neural bots</title><link href="http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots/" rel="alternate" type="text/html" title="Zombie bots and neural bots" /><published>2023-09-08T00:00:00+00:00</published><updated>2023-09-08T00:00:00+00:00</updated><id>http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots</id><content type="html" xml:base="http://localhost:4000/artificial_intelligence/zombie-bots-and-neural-bots/">&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/nbot-2.gif&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We all know that neural networks are taking over the world. We see this in the deep learning revolution, in the wonders of deep reinforcement learning and of large language models. These advances combine Big Tech, Big Data and Big Bucks. But the underlying ideas are simple and very powerful, and in this blog I want to share some toy examples that I first played with about 10 years ago.&lt;/p&gt;

&lt;p&gt;I’ll explain the animation above as we go — but basically the moving dot is a bot that’s evolved to seek out and eat red squares, using a brain with just 16 neurons, the output of which are shown, as time progresses, in the blue graph.&lt;/p&gt;

&lt;p&gt;Everything is written in straight C++, with no TensorFlow or other advanced libraries. I’ll talk about the code in another post, but here I just want to focus on the ideas. All training will be by genetic algorithms (as I’ll explain) and not by gradient descent — this immediately simplifies things for us.&lt;/p&gt;

&lt;p&gt;Here’s the task. A bot lives in a 2D binary array, and is to be programmed to efficiently find all the 1s (coloured red in the animations). At each step, the bot can only see 5 immediately adjacent squares (its own, and those to left, right, up and down); each of these can be in one of three states (0,1 or boundary (i.e. non-existent)). And it has 5 actions to choose from: move left, right, up or down, or ‘eat’ the (value of the) current square.&lt;/p&gt;

&lt;p&gt;The first type of program we might think of — let’s call this a zombie bot — consists simply of a 3⁵ = 243-long lookup table of moves, such as:&lt;/p&gt;

&lt;p&gt;304103402202214122102102401303313302201214404102104044203101340202201110102102131401314403344204304401104402441113401241114400300214110441400423443014321343143134201104301204102220314421441333434304333332331233340312101100402201101131422114214&lt;/p&gt;

&lt;p&gt;In other words, for each one of the 3⁵ possible states, just look up the corresponding number from 0 to 4 and take that as the action to follow.&lt;/p&gt;

&lt;p&gt;Challenge: can you design this ‘program’ — i.e. the sequence of digits — to get an optimally efficient bot? (Well, it turns out that optimality is impossible, as we’ll see in a moment.)&lt;/p&gt;

&lt;p&gt;Let’s suppose you’ve done that, and are ready to test your solution against nature’s. So what might nature’s be? Here’s a genetic algorithm approach:&lt;/p&gt;

&lt;p&gt;Let’s call the above lookup table the bot’s genome, and assume that two bots are able to have sex (resulting in two children) by choosing a random partition of their genomes, swapping alternating portions, and then applying some low-probability mutation to each offspring. We then initialise a suitably-sized population, implement sex freely in that population, and retain at each generation only those bots with the best ability to collect 1s (i.e. find red squares). In other words, we’re running a genetic algorithm to optimise a fitness function (which consists of a suitable test regime for hopeful bots).&lt;/p&gt;

&lt;p&gt;OK … so here’s a typical zombie bot after 10 generations of evolution from a random initalisation :grimacing:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-10.gif&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And after 500 generations :worried:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-500.gif&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And after 2000 generations :blush:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/zbot-2000.gif&quot; width=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At this point — quite surprisingly — the bot has evolved a ‘reconnaisance’ strategy. You might notice that sometimes when the bot enters a patch of red, it doesn’t start eating immediately, but instead travels to one end of the patch, and then systematically eats its way back across the whole patch. This is clearly a better strategy than to arbitrarily eat in one direction or the other, which would create two islands one of which it cannot easily find its way back to. (Did your hand-crafted program think about this?)&lt;/p&gt;

&lt;p&gt;The zombie bot is therefore well adapted to its task — but it’s not optimal. At the end, it finds itself running round the boundary, unable ever to find its way back to the interior to explore for left-over bits. Since it runs on a fixed lookup table, this is inevitable.&lt;/p&gt;

&lt;p&gt;Now meet the neural bot. This has a genome consisting of 416 real numbers, which are weights of a recurrent neural network with 16 hidden units:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/botnet.png&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the very simplest type of recurrent neural network — and as the diagram suggests, we interpret the input bit vector as defining the current ‘sensory’ state, and the output as defining a ‘motor’ decision.&lt;/p&gt;

&lt;p&gt;(Today, recurrent networks have evolved beyond recognition from this simplest version — from LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Units) to today’s Transformer models. But many of these advances were in response to the challenge of training by gradient descent — for a small task, our example avoids that problem altogether by training with a genetic algorithm.)&lt;/p&gt;

&lt;p&gt;Treating the weights of the network as a ‘genome’, we can now evolve the neural bots in exactly the same way as their zombie counterparts. As we do so, we have at any point in time a population of bots, and we can observe them as individuals. We find that even at this very simple level they demonstrate different ‘personalities’. Here are two examples:&lt;/p&gt;

&lt;p&gt;The first is the one pictured at the top of this post (accompanied by the output of its 16 hidden units at each time step). Take another look.&lt;/p&gt;

&lt;p&gt;This bot is able to move diagonally. That would be impossible for a zombie bot, for which the state uniquely determines the action. And consistent diagonal action requires short-term memory, which is somehow encoded in its 16-bit brain. The bot chooses between diagonal and straight-line travel, in the quest to hoover up red squares.&lt;/p&gt;

&lt;p&gt;The second bot I want to show you is lazier, and has evolved a near-optimal strategy of simply marching up and down, systematically ignoring the bits in the next row it’s coming to. Its laziness (or efficiency) is even visible in its mental state: it clearly has more brain cells than it uses!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-09-08/nbot-1.gif&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="artificial_intelligence" /><summary type="html"></summary></entry><entry><title type="html">How to code interactive graphics with R shiny</title><link href="http://localhost:4000/data_science/coding-interactive-graphics/" rel="alternate" type="text/html" title="How to code interactive graphics with R shiny" /><published>2023-03-07T00:00:00+00:00</published><updated>2023-03-07T00:00:00+00:00</updated><id>http://localhost:4000/data_science/coding-interactive-graphics</id><content type="html" xml:base="http://localhost:4000/data_science/coding-interactive-graphics/">&lt;p&gt;&lt;a href=&quot;https://billox.shinyapps.io/zip-topological-viz/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/img/2023-03-07/shiny-app.png&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My earlier blog &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;A Topological Trick for Data Visualisation&lt;/a&gt; described Carlsson’s &lt;i&gt;mapper&lt;/i&gt; construction, that offers a good graph representation of a high-dimensional point cloud. I offered a fancy interactive demo of &lt;i&gt;mapper&lt;/i&gt; on the Zip data set of hand-written digits – shown in the graphic above and linked to it.&lt;/p&gt;

&lt;p&gt;In that blog, I focussed on the mathematical idea behind &lt;i&gt;mapper&lt;/i&gt; and said nothing about how the demo worked. In this blog, I want to say a little bit about the &lt;a href=&quot;https://shiny.rstudio.com/&quot; target=&quot;_blank&quot;&gt;R shiny&lt;/a&gt; code behind the demo, in order to make it a bit more reproducible for interested readers.&lt;/p&gt;

&lt;p&gt;For those already familiar with R, &lt;i&gt;shiny&lt;/i&gt; provides a very easy way to build interactive graphics using the R language. There are lots of good tutorials to be found, so all I’ll say by way of introduction is that a &lt;i&gt;shiny&lt;/i&gt; application is basically defined by two functions &lt;i&gt;shinyUI()&lt;/i&gt; and &lt;i&gt;shinyServer()&lt;/i&gt;, usually saved in their own source files &lt;i&gt;UI.R&lt;/i&gt; and &lt;i&gt;server.R&lt;/i&gt;. A first example to look at is &lt;a href=&quot;https://shiny.rstudio.com/gallery/example-01-hello.html&quot; target=&quot;_blank&quot;&gt;Hello Shiny!&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, with that said, the UI code for the fancy &lt;i&gt;mapper&lt;/i&gt; demo is simply the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;shinyUI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fluidPage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titlePanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;A topological trick for data visualisation&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sidebarLayout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;right&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sidebarPanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sliderInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;nbins&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Resolution (nr bins):&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sliderInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;klevel&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Resolution (heirarchical cluster k):&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numericInput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;obsvertex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Sample vertex:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plotOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;digitview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mainPanel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plotOutput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;graphview&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This says that there’s a side panel with some controls plus a plot output &lt;i&gt;“digitview”&lt;/i&gt;, and a main panel with another plot output &lt;i&gt;“graphview”&lt;/i&gt;. These two plot outputs will be defined in the server file, which we’ll look at in a moment.&lt;/p&gt;

&lt;p&gt;Besides these two outputs, we also see three &lt;i&gt;“input”&lt;/i&gt;s in the sidebarpanel. These define variables (for example &lt;i&gt;input$nbins&lt;/i&gt;) that are picked up from the UI and used by the server function. This repeats the pattern you see in the &lt;a href=&quot;https://shiny.rstudio.com/gallery/example-01-hello.html&quot; target=&quot;_blank&quot;&gt;Hello Shiny!&lt;/a&gt; app.&lt;/p&gt;

&lt;p&gt;So next, the server file:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;helpers.R&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# stores some functions needed below&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# the Zip data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shinyServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        
    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# build clusters:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reactive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make.clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nbins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;klevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mg&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reactive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapper.graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    
    &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# outputs:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;graphview&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;renderPlot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show.graph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obsvertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;digitview&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;renderPlot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show.digits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cluster.set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obsvertex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Again, the structure is simple. Starting at the bottom of this code, the two outputs &lt;i&gt;“digitview”&lt;/i&gt; and  &lt;i&gt;“graphview”&lt;/i&gt; are defined. Each of these calls &lt;i&gt;renderPlot()&lt;/i&gt;, which gives a reactive version of some plotting code for passing to the server output that gets picked up by the UI.&lt;/p&gt;

&lt;p&gt;For the two cases, the plotting code is defined by functions &lt;i&gt;show.graph()&lt;/i&gt; and &lt;i&gt;show.digits()&lt;/i&gt; – which I’ve defined in a source file &lt;i&gt;‘helpers.R’&lt;/i&gt;, and I’ll come to in a moment.&lt;/p&gt;

&lt;p&gt;These two functions depend on the data clusters, and the graph structure on these clusters, as I’ve described conceptually in the &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;previous blog&lt;/a&gt;. And they depend on these via the user inputs &lt;i&gt;nbins, klevel, obsvertex&lt;/i&gt;. These variables change in response to the UI controls, so the functions &lt;i&gt;mg(), cluster.set()&lt;/i&gt; are defined to be ‘reactive’ – that is, to link in real time to the input variables.&lt;/p&gt;

&lt;p&gt;At this point you can see that the work of implementing the construction I described in the &lt;a href=&quot;https://billoxbury.github.io/data_science/topological-trick-for-data-visualisation/&quot; target=&quot;_blank&quot;&gt;previous blog&lt;/a&gt; is wrapped up in the functions &lt;i&gt;make.clusters()&lt;/i&gt;, &lt;i&gt;mapper.graph()&lt;/i&gt;, &lt;i&gt;show.graph()&lt;/i&gt; and &lt;i&gt;show.digits()&lt;/i&gt;. I won’t go into all of these in gory detail. The reader should get the idea of the first two from the previous blog.&lt;/p&gt;

&lt;p&gt;But I will say a bit about &lt;i&gt;show.graph()&lt;/i&gt;, as this uses the excellent library &lt;a href=&quot;https://igraph.org/&quot; target=&quot;_blank&quot;&gt;igraph&lt;/a&gt; and the reader may or may not be familiar with this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;n&quot;&gt;show.graph&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# connected components of igraph object g&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# edge parameters&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;grey&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow.mode&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curved&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex - size by cluster size&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.cex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.cex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex label by most common digit in the cluster&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]];&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# vertex - colour by connected component&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frame.color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;membership&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label.color&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;membership&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# highlight the selected base vertex&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;orange&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  
  &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# output igraph plot&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The function takes inputs a graph &lt;i&gt;g&lt;/i&gt; (an &lt;i&gt;igraph&lt;/i&gt; object), a cluster set (of vertex indices) &lt;i&gt;cset&lt;/i&gt; and a selected vertex &lt;i&gt;v&lt;/i&gt; (set as -1, or ‘none’ by default). It outputs a plot that looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-03-07/zip2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html"></summary></entry><entry><title type="html">Language barriers in global conservation</title><link href="http://localhost:4000/environment/language_barriers/" rel="alternate" type="text/html" title="Language barriers in global conservation" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>http://localhost:4000/environment/language_barriers</id><content type="html" xml:base="http://localhost:4000/environment/language_barriers/">&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-02-22/birdclouds.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Wildlife tends not to respect national boundaries. Birds, in particular, as they migrate across and between continents, ignore not only borders but even the cultures and languages of the scientists who may be trying to study and protect them. And, surprise surprise, not all of the world’s science is written in English.&lt;/p&gt;

&lt;p&gt;According to a recent study [1], more than 30% of scientific articles on biodiversity conservation are written in non-English languages. Moreover, the authors claim that non-English language scientific outputs – at least within biodiversity conservation – are increasing both in volume and in quality. In geographic regions where English is not widely used – as in some of the world’s biodiversity hotspots – key data and evidence are generated by local scientists and even by citizen science projects in local languages. So when it comes to tracking species with global geographic ranges, restricting only to English-language scientific outputs can lead to key gaps in knowledge.&lt;/p&gt;

&lt;p&gt;The study [2] takes a closer look at this issue for bird species. They compare the known geographic ranges of more than 10,000 species with the official languages listed for the countries covered by those ranges. They show that more than 1,500 species have coverage of at least 10 languages. High numbers of ‘multi-lingual’ species have ranges spanning Eastern Europe, Russia and central Asia. Nevertheless, they also observe that four European languages – English, Spanish, Portuguese and French – dominate species coverage globally, each reaching between 3,000 and 6,000 bird species.&lt;/p&gt;

&lt;p&gt;In a project for &lt;a href=&quot;https://www.birdlife.org/&quot; target=&quot;_blank&quot;&gt;BirdLife International&lt;/a&gt;, I have been able to put some of these observations to the test, from the complementary perspective of what can be seen directly in the scientific literature. &lt;i&gt;LitScan&lt;/i&gt; is a system to crawl and identify scientific articles of relevance to Red List assessments. It scans various sources across multiple languages; makes use of &lt;a href=&quot;https://spacy.io/&quot; target=&quot;_blank&quot;&gt;spaCy&lt;/a&gt; for text-processing (including language id, discovery of species mentions and conservation relevance); and uses Cloud cognitive services for translation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2023-02-22/Picus_viridis.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the purposes of this blog post – and for comparison with the results of [2] – I want to focus on just one of the &lt;i&gt;LitScan&lt;/i&gt; sources &lt;a href=&quot;https://openalex.org/&quot; target=&quot;_blank&quot;&gt;OpenAlex&lt;/a&gt; [3]. This is an extremely useful open-source repository of metadata for scientific documnents drawing on an impressive &lt;a href=&quot;https://openalex.org/about&quot; target=&quot;_blank&quot;&gt;range of sources&lt;/a&gt;. I don’t know what the exact language coverage of OpenAlex is (and I’m sure it could be improved), but I can make some observations based on &lt;i&gt;LitScan&lt;/i&gt;.&lt;/p&gt;

&lt;p&gt;(Incidentally, besides OpenAlex, &lt;i&gt;LitScan&lt;/i&gt; taps directly into various non-English sources. These are quite specific and would bias any comparison with [2], so in this post I’ll just restrict to &lt;i&gt;LitScan&lt;/i&gt; data that comes from OpenAlex.)&lt;/p&gt;

&lt;p&gt;So here’s a data set – used by &lt;i&gt;LitScan&lt;/i&gt; but constructed as follows. Over a 3-month period a daily request was made to OpenAlex. The request consisted of 500 searches, each on the scientific name of a bird species drawn at random from a list of 11,188. The searches are not all successful, and over the collection period the number of documents returned – after some additional filtering for conservation relevance and publication since the year 2000 – was 35,303 (so averaging about 400 per day).&lt;/p&gt;

&lt;p&gt;The total number of species covered by these documents was 3,517, in a total of 32 languages – by far dominated by English (32,239 documents), with the next most numerous language being Spanish (824 documents).&lt;/p&gt;

&lt;p&gt;We can now ask, in the spirit of [2]: &lt;b&gt;how many species&lt;/b&gt; are found in &lt;b&gt;non-English documents only&lt;/b&gt;? Moreover, since we are interested in conservation relevance, we can ask for this number broken down by red-list status – as defined by the &lt;a href=&quot;https://www.iucnredlist.org/&quot; target=&quot;_blank&quot;&gt;IUCN Red List of Threatened Species&lt;/a&gt; – as well as language:&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&quot;text-align:left;&quot;&gt;   &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; LC &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; NT &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; VU &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; EN &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; CR &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; EX &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Spanish &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 211 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 13 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 14 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Portuguese &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 52 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 11 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 7 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 5 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Indonesian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 29 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 11 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; French &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 25 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 8 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 3 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; German &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 5 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Korean &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 4 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Mandarin &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Czech &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Catalan &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Norwegian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Croatian &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(The columns are the red-list categories &lt;i&gt;Least Concern&lt;/i&gt;, &lt;i&gt;Near Threatened&lt;/i&gt;, &lt;i&gt;VUlnerable&lt;/i&gt;, &lt;i&gt;ENdangered&lt;/i&gt;, &lt;i&gt;CRitically endangered&lt;/i&gt; and &lt;i&gt;EXtinct&lt;/i&gt;.)&lt;/p&gt;

&lt;p&gt;These are small numbers, but every species counted in this table represents information that may be lost to red-list assessors who have access only to English-language science. Moreover, many more species are represented in both English and non-English documents (and so are not counted here).&lt;/p&gt;

&lt;p&gt;The document sampling using OpenAlex is far from unbiased – clearly we have not tapped into a much wider literature in, say, Mandarin or Korean. The &lt;i&gt;LitScan&lt;/i&gt; ambition is to maximise the use of sources in those languages directly in the future. Nevertheless, the analysis offers an interesting corroboration of the observations in [1,2].&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;T. Amano et al: &lt;a href=&quot;https://doi.org/10.1371/journal.pbio.3001296&quot; target=&quot;_blank&quot;&gt;Tapping into non-English language science for conservation of global biodiversity&lt;/a&gt;, PLOS Biology (2021) &lt;i&gt;doi: 10.1371/journal.pbio.3001296&lt;/i&gt;&lt;/li&gt;
  &lt;li&gt;Pablo Jose Negret, Scott C. Atkinson, Bradley K. Woodworth, Marina Corella Tor, James R. Allan, Richard A. Fuller, Tatsuya Amano: &lt;a href=&quot;https://doi.org/10.1371/journal.pone.0267151&quot; target=&quot;_blank&quot;&gt;Language barriers in global bird conservation&lt;/a&gt; PLOS One (2022) &lt;i&gt;doi: 10.1371/journal.pone.0267151&lt;/i&gt;&lt;/li&gt;
  &lt;li&gt;Priem, J., Piwowar, H., &amp;amp; Orr, R. (2022). &lt;a href=&quot;https://openalex.org/&quot; target=&quot;_blank&quot;&gt;OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts&lt;/a&gt; (2022) &lt;i&gt;arXiv: &lt;a href=&quot;https://arxiv.org/abs/2205.01833&quot; target=&quot;_blank&quot;&gt;arxiv.org/abs/2205.01833&lt;/a&gt;&lt;/i&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">Navigating the PLOS ONE topic tree</title><link href="http://localhost:4000/data_science/plosone-topic-tree/" rel="alternate" type="text/html" title="Navigating the PLOS ONE topic tree" /><published>2022-02-10T00:00:00+00:00</published><updated>2022-02-10T00:00:00+00:00</updated><id>http://localhost:4000/data_science/plosone-topic-tree</id><content type="html" xml:base="http://localhost:4000/data_science/plosone-topic-tree/">&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/browse_topics.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PLOS ONE is a respected multidisciplinary journal publishing research from&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;over two hundred subject areas across science, engineering, medicine, and the related social sciences and humanities.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But exactly &lt;strong&gt;how many&lt;/strong&gt; subject areas?&lt;/p&gt;

&lt;p&gt;At the top level (as shown in the screenshot above), these subject areas fall under eleven headings from &lt;em&gt;Biology and life sciences&lt;/em&gt; to &lt;em&gt;Social sciences&lt;/em&gt;. For each of these headings – such as &lt;em&gt;Computer and information sciences&lt;/em&gt; below - we are told the number of articles (in this case 32,397) and can browse further subheadings:&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2022-02-10/compsci_count.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2022-02-10/compsci_topics.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p&gt;This post is about a short exercise to scan the entire tree of PLOS ONE topics, asking:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;how does one extract and represent this tree?&lt;/li&gt;
  &lt;li&gt;are the article counts per topic &lt;em&gt;consistent&lt;/em&gt; e.g. in the sense that each count is the sum of the counts at the leaves of the corresponding subtree?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Visually, the result of the analysis is plots such as the following (the topic trees of some of the top-level headings):&lt;/p&gt;

&lt;embed src=&quot;/assets/img/2022-02-10/seven_trees.pdf&quot; type=&quot;application/pdf&quot; frameborder=&quot;0&quot; scrolling=&quot;auto&quot; height=&quot;100%&quot; width=&quot;100%&quot; /&gt;

&lt;h2&gt;1. Crawling&lt;/h2&gt;

&lt;p&gt;The starting task was to crawl the PLOS ONE pages. To do this, we initialise a data frame with a single row (I’ll use Python-like pseudocode throughout - most of this exercise was actually done in R):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;node&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;s&quot;&gt;&apos;parent&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;s&quot;&gt;&apos;parent_topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;… and then add tree nodes to the data frame via the following breadth-first search:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;browse_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://journals.plos.org/plosone/browse/&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;browse_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# read HTML
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;next_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# read HTML    
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;topic_tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;node&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;parent&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                          &lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;parent_topic&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this_topic&lt;/span&gt;
                          &lt;span class=&quot;s&quot;&gt;&apos;count&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
                          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this code, the functions &lt;tt&gt;find_count()&lt;/tt&gt; and &lt;tt&gt;find_children()&lt;/tt&gt; parse the HTML of the currently visited topic page and extract the count and subtopics respectively. (For this I use the package &lt;em&gt;rvest&lt;/em&gt; in R.)&lt;/p&gt;

&lt;h2&gt;2. Counting&lt;/h2&gt;

&lt;p&gt;The code generates a data frame with &lt;i&gt;(as of 9 Feb 2022)&lt;/i&gt; a total of 16,721 rows (topics). From this data frame we can read off any tree statistics - for example the node count by depth in the tree:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/count_by_depth.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To illustrate the data frame, the following slice is the part of the tree below node 49, &lt;i&gt;sports_science&lt;/i&gt;. (This is an example of a &lt;em&gt;clade&lt;/em&gt;: a subtree that exactly consists of one node and all its descendants:)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/sports_tree0.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2022-02-10/sports_tree1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first thing to note is that the article counts (as read off from the PLOS ONE topic pages) are not in any sense consistent! (That was question 2 at the top of this post.)&lt;/p&gt;

&lt;p&gt;At each node, we can read off an &lt;strong&gt;excess count&lt;/strong&gt;, which is the difference between the advertised article count and the sum of the counts at child nodes. This excess is usually positive: for example, at the topic &lt;em&gt;exercise&lt;/em&gt; the excess is 1,515 - the number of articles that presumably do not fall under the subtopics of &lt;i&gt;aerobic_exercise&lt;/i&gt; or &lt;i&gt;strength_training&lt;/i&gt;. This is to be expected if the topic tree grows over time with new subtopics being added to the &lt;a href=&quot;https://github.com/PLOS/plos-thesaurus&quot; target=&quot;_blank&quot;&gt;PLOS thesaurus&lt;/a&gt;. On the other hand, the excess count is often negative. For example, the count at &lt;i&gt;sports_science&lt;/i&gt; is actually &lt;em&gt;less than&lt;/em&gt; the counts at its two subtopics &lt;i&gt;sports&lt;/i&gt; and &lt;i&gt;sports_and_exercise_medicine&lt;/i&gt;. At some point, the parent node has stopped counting!&lt;/p&gt;

&lt;p&gt;(It turns out that the excess count has a large negative value at all of the 11 top-level topics – which are therefore underestimating the number of articles they cover.)&lt;/p&gt;

&lt;h2&gt;3. Drawing&lt;/h2&gt;

&lt;p&gt;Finally, a word about tree formats and visualisation. The circular plots shown above could have been made using a package like R &lt;em&gt;phylotools&lt;/em&gt;. In fact, I took a shortcut and used the very convenient &lt;a href=&quot;https://itol.embl.de/&quot; target=&quot;_blank&quot;&gt;Interactive Tree Of Life (iTOL)&lt;/a&gt; site.&lt;/p&gt;

&lt;p&gt;In either case, a more compact data format is needed than the data frame shown above. A popular format that I used is the &lt;strong&gt;Newick format&lt;/strong&gt;. The idea of Newick format is that the tree is represented by a string with the recursive form&lt;/p&gt;

&lt;p&gt;\[
\nu({\rm tree}) = (\nu({\rm child}_1),\ldots,\nu({\rm child}_k))\nu({\rm root})
\]&lt;/p&gt;

&lt;p&gt;and where $\nu({\rm single\ node})$ is any convenient string representing that node, e.g. the topic name. Converting from the data frame shown above to Newick format is then achieved with a simple recursive function:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;(&quot;&lt;/span&gt;                           &lt;span class=&quot;c1&quot;&gt;# open bracket
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;children&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# insert commas-separated child strings
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;,&apos;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;,&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;# remove final comma
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;)&apos;&lt;/span&gt;                          &lt;span class=&quot;c1&quot;&gt;# close bracket
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;topic&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;               &lt;span class=&quot;c1&quot;&gt;# append parent string
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Applied to the little &lt;i&gt;sports_science&lt;/i&gt; data frame this outputs:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newickR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&apos;(sports,((aerobic_exercise,strength_training)exercise)sports_and_exercise_medicine)sports_science&apos;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html"></summary></entry><entry><title type="html">COP26: seeing the wood for the trees</title><link href="http://localhost:4000/environment/cop26-nzs/" rel="alternate" type="text/html" title="COP26: seeing the wood for the trees" /><published>2021-11-03T00:00:00+00:00</published><updated>2021-11-03T00:00:00+00:00</updated><id>http://localhost:4000/environment/cop26-nzs</id><content type="html" xml:base="http://localhost:4000/environment/cop26-nzs/">&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-03/woodfortrees1.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The climate crisis poses an almost overwhelming challenge to humanity, and it is very easy to be pessimistic. But there are also some reasons to be hopeful. Many will have been inspired by Prince William’s Earthshot initiative, by the vision behind it and the passion and creativity of the finalists and other innovators. It gives me genuine hope that we have the capacity to correct our course for a safe future.&lt;/p&gt;

&lt;p&gt;You will hear about many innovations and tech solutions for sustainability in the margins of COP26. However, the success of the conference will stand or fall on one thing only: the ability of the international community to agree a practical pathway to achieve the 1.5°C goal of the Paris agreement.&lt;/p&gt;

&lt;p&gt;This is ultimately a numbers game. One of the most hopeful conclusions from the 
&lt;a href=&quot;https://www.ipcc.ch/report/ar6/wg1/#FullReport&quot;&gt;2021 IPCC 6th Assessment Report&lt;/a&gt;
 is that there is a strong linear relationship between the average global temperature we arrive at this century and the total volume of carbon that we emit into the atmosphere from today. In other words, the world has an emissions ‘budget’: the lower the budget, the lower the final temperature rise.&lt;/p&gt;

&lt;p&gt;To understand the budget choices, the following table is from the IPCC report:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-03/image1.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The table expresses uncertainties and margins of error. Sorry. But it’s the best science we have to go on, so let’s see what it says.&lt;/p&gt;

&lt;p&gt;The rows of the table express budgets (in GtCO2, or giga-tonnes of CO2 emission) for limiting the global temperature rise to values on the left-hand margin, with likelihood expressed in the top margin. So, for example, 500 GtCO2 buys a 50% chance of staying within 1.5°C in this century. Let’s go with that for the moment – assuming a 50% chance feels a safe enough bet for you.&lt;/p&gt;

&lt;p&gt;So how much is 500 GtCO2? For comparison, the world in 2020 released approximately 40 GtCO2 (with the UK responsible for about 0.3 GtCO2 of that). So at current rates, 500 equates to about 12 years. Or if we could assume a 7% worldwide reduction in emissions every year, then it buys us 30 years.&lt;/p&gt;

&lt;p&gt;(Two more comparisons: the proposed coking coal mine at Woodhouse Colliery would commit the UK to about 0.16 GtCO2 from the coal extracted over the lifetime of the mine; the Cambo oil field in the North Sea commits us to about 0.3 GtCO2. Both would eat significantly into any reasonable budget for the UK.)&lt;/p&gt;

&lt;p&gt;This is the numbers game that COP26 has to solve in order to ensure a safe future. What emissions budget can the international community agree that will set an acceptable level of temperature risk? Given that budget, how will it be divided equitably among nations? And how do we support poorer nations to live within their budget as they transition to a zero-carbon future?&lt;/p&gt;

&lt;p&gt;All too often, responding to the climate crisis is framed as being about personal choices (you should fly less, you should eat less meat). It isn’t. Ultimately, it depends on science-driven policies, tireless diplomacy and international cooperation to shift those big carbon numbers. COP26 is a critical part of that process.&lt;/p&gt;

&lt;p&gt;Yes, our lifestyles will change, and individual choices are important – but for the majority they’ll change the way they always have done: in response to better choices coming along through vision, investment and legislation.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">COP26: why 1.5 degrees?</title><link href="http://localhost:4000/environment/cop26-why1pt5/" rel="alternate" type="text/html" title="COP26: why 1.5 degrees?" /><published>2021-11-02T00:00:00+00:00</published><updated>2021-11-02T00:00:00+00:00</updated><id>http://localhost:4000/environment/cop26-why1pt5</id><content type="html" xml:base="http://localhost:4000/environment/cop26-why1pt5/">&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image1.jpeg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the 2015 Paris Agreement, countries of the world signed up to &lt;em&gt;“keep the rise in average global temperature to well below 2°C above pre-industrial levels, and preferably limit the increase to 1.5°C”&lt;/em&gt;.  This month’s COP26 summit is the last best chance for nations to agree plans of action to achieve that goal. For the reasons I discussed in the previous blog, it’s vital for all our futures that we succeed.&lt;/p&gt;

&lt;p&gt;So why 1.5°C? The figure sounds insignificant – what does it mean?&lt;/p&gt;

&lt;p&gt;Global average temperature is not a flat, uniform thing. It’s more like the surface of the sea – it has peaks and troughs. And actually, as the average rises, so does the variation between those peaks and troughs. The graphic above, taken from the &lt;a href=&quot;https://www.atlasoftheinvisible.com/&quot;&gt;Atlas of the Invisible&lt;/a&gt;, illustrates this. Each square is a little map of the Earth, showing average temperature from 1890 to 2019. The colour, from blue to red, shows how far the temperature is below or above the global average for the ‘baseline period’ (1960s to 1980s). What you see is not only the trend but the variation across the planet.&lt;/p&gt;

&lt;p&gt;So a total average temperature rise of 1.1°C (above the pre-industrial average, which is roughly where we are today), affects different parts of the planet in different ways, and has led to the big effects in terms of extreme weather, melting ice and changing rainfall patterns that we see today.&lt;/p&gt;

&lt;p&gt;Let’s put that figure of 1.1°C in historical context. The following graphic is taken from the &lt;a href=&quot;https://www.ipcc.ch/report/ar6/wg1/#FullReport&quot;&gt;IPCC’s 6th Assessment Report&lt;/a&gt; this summer. It shows that insignificant-looking temperature difference in the context of the last two thousand years. In this context, we see that 1.1°C is a very big deal and that the rise is not gradual but is better thought of as a shock to the system.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image2.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The graphic also shows that today’s temperature is outside anything the planet has experienced in the past 100,000 years. At 1.5°C we will already head beyond any conditions that have existed during the lifetime of our species. Yet the IPCC report makes clear that we are very likely to exceed 1.5°C by 2040 and possibly by 2030. Without radical actions agreed at COP26, according to the IPCC, we are heading past 2.4°C by 2040 and to around 4.0°C by the end of the century.&lt;/p&gt;

&lt;p&gt;A temperature rise of 4.0°C is pretty unthinkable. In geological time it takes us back nearly 50 million years to an age before primates had evolved and when the poles were temperate. The sea level rise this would induce would drown all the major coastal cities in the world.&lt;/p&gt;

&lt;p&gt;A major risk of permitting uncontrolled temperature rise is the existence of tipping points in the Earth system – temperature levels at which global processes will kick in that would send the temperature rise higher still. The graphic below, by Tim Lenton, illustrates these tipping points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-02/image3.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So the threats are real and current climate change is very much a crisis. But it is still not too late in the day, and there is no doubt that humanity has the ingenuity and resourcefulness to rise to the challenge. Rising to the challenge is just what we have to look to COP26 to do.&lt;/p&gt;

&lt;p&gt;The problem to be solved is stated as a number, 1.5 degrees – so any solutions have to play a numbers game. I’ll talk about that in the last blog.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">COP26: the climate crisis today</title><link href="http://localhost:4000/environment/cop26-today/" rel="alternate" type="text/html" title="COP26: the climate crisis today" /><published>2021-11-01T00:00:00+00:00</published><updated>2021-11-01T00:00:00+00:00</updated><id>http://localhost:4000/environment/cop26-today</id><content type="html" xml:base="http://localhost:4000/environment/cop26-today/">&lt;p&gt;&lt;img src=&quot;/assets/img/2021-11-01/image1.png&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the first of three blogs in which I’d like to share a few thoughts on the climate crisis and on the COP26 conference which launches in Glasgow this week. In the &lt;a href=&quot;/environment/cop26-why1pt5/&quot;&gt;second blog&lt;/a&gt; I’ll say a bit about the figure of 1.5 degrees warming and what it means; in the &lt;a href=&quot;/environment/cop26-nzs/&quot;&gt;third&lt;/a&gt; I’ll focus on COP itself.&lt;/p&gt;

&lt;p&gt;But let’s start with today. As we look back over the summer of 2021, we’ve seen a number of tragic events in the news: the Pacific North-West of the US and Canada was hit by a ‘heat dome’ killing more than 500 people – as well as up to a billion marine animals. Southern Europe was hit by record wildfires killing many people in Greece, Italy and Portugal. Wildfires in Siberia were reported to be larger than the rest of the world’s combined – as rain was observed on the summit of the Greenland icecap for the first time. During the same few weeks major floods hit China (302 deaths), Germany (196 deaths), Belgium (42 deaths), Mexico (17 deaths) and Pakistan (160 deaths). Back in the US, hurricane Ida travelled up the east coast from Louisiana to New York with a death toll of 82.&lt;/p&gt;

&lt;p&gt;This is just a snapshot of recent times. The climate crisis, and our response to it, is not just about ‘saving the planet’, it’s about saving lives. And extreme weather is not a ‘new normal’ – because the Earth system is in a state of transition and will take many decades, or even centuries, to settle into a new stable state.&lt;/p&gt;

&lt;p&gt;The climate crisis is also about national security. Our security depends not only on safety from wildfires and floods, but also on resilient infrastructure, a stable economy and secure food and water supplies. It depends on stable international relationships and supply chains and the ability of our people, from tourists and business people to diplomats and military personnel, to travel and operate safely overseas.&lt;/p&gt;

&lt;p&gt;The evolving threat around the world is not only from extreme weather events. It’s also from changing rainfall patterns and failing agriculture, from depleted water sources and from sea level rise and storm surges. It will drive tensions over these resources and over displaced populations.
The graphic at the top of this post, illustrating some of these cascading risks to security, is taken from a &lt;a href=&quot;https://www.chathamhouse.org/2021/09/climate-change-risk-assessment-2021&quot;&gt;recent Chatham House report&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;According to the &lt;a href=&quot;https://imccs.org/the-world-climate-and-security-report-2021/&quot;&gt;World Climate and Security Report (WCSR) 2021&lt;/a&gt;, “within the next twenty years, security risks stemming from climate phenomena will present severe and catastrophic levels of risk”. That’s a stark message, and I shall offer a bit more optimism in the third of these blogs. But there is no doubt that as the crisis unfolds it will affect the politics, rivalries and stability of all nations.&lt;/p&gt;

&lt;p&gt;Examples cited in the WCSR report include: floods in Sudan in 2020 exacerbating the country’s already fragile security infrastructure, as well as requiring assistance from the Egyptian military for humanitarian aid; the impact of recent floods and wildfires on US military bases and equipment; and increased tensions in the Arctic. China’s economic dominance in the 21st century is argued to be “not guaranteed” because of the dense concentration of population and economic hubs in cities most at risk from sea level rise and from water shortages. Russia may perceive that it is less at risk from climate change than other countries, yet it is vulnerable both from the threat to infrastructure of melting permafrost, and from exposed fossil fuel assets if the world succeeds in shifting rapidly to renewable energy sources.&lt;/p&gt;

&lt;p&gt;These are just examples of the ways in which the climate crisis will have deep implications for behaviours and intents of nation states. So the COP26 conference matters to us. It is a milestone event which will have huge implications for the direction that humanity takes. I’ll say a bit about the problem it has to solve in the next two blogs.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="environment" /><summary type="html"></summary></entry><entry><title type="html">Watching a neural network learn a Markov chain</title><link href="http://localhost:4000/data_science/rnn-learns-markov/" rel="alternate" type="text/html" title="Watching a neural network learn a Markov chain" /><published>2019-11-01T00:00:00+00:00</published><updated>2019-11-01T00:00:00+00:00</updated><id>http://localhost:4000/data_science/rnn-learns-markov</id><content type="html" xml:base="http://localhost:4000/data_science/rnn-learns-markov/">&lt;p&gt;Modern language models derive their power from big data and big compute – but also, ultimately, from the &lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot; target=&quot;_blank&quot;&gt;Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt; described by Andrej Karpathy (and many others) a decade or so ago. This post is more low-brow than Karpathy’s — I wanted to explore a little bit how RNNs perform on some carefully controlled toy data: specifically on sequences generated from Markov chains.&lt;/p&gt;

&lt;p&gt;What does it mean to model a sequence? It means two things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Given a new sequence generated by the same process, can we predict at each time step the next sequence item?&lt;/li&gt;
  &lt;li&gt;Does the ‘model’ give simplying insights into this underlying process?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Suppose, for example, that the sequence is drawn from an ‘alphabet’ of $N$ distinct symbols, and that the process generating the sequence is Markov — in other words, each item depends only on its predecessor. In that case, problem 1 is completely solved in $O(N^2)$ storage by just collecting enough data and observing conditional frequencies. This does nothing to address problem 2, however. On the other hand, fitting an $n$-state hidden Markov model (HMM) reduces the storage to $O(nN)$. So it improves the solution to problem 1 — but it also answers problem 2 if we can interpret what the ‘hidden states’ mean.&lt;/p&gt;

&lt;p&gt;However, most sequences generated by processes of interest are not 1-st order Markov. If the process is Markov of order $k$, then the storage requirement for the naive solution is $O(Nk)$, which rapidly becomes intractable. This is where RNNs come in. At least, they appear to perform well on problem 1. What about problem 2? Can we extract any understanding from them?&lt;/p&gt;

&lt;p&gt;Here’s an example. It’s a stretch of ASCII sequence (from a source which I’ll reveal in a moment):&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;
ikkviiviiekotkiwiwiieeiiioikttooiotkkeiiokkttkkiwvvwtkikweiwvwikkkiokkwookkkkoiikiieiiiwoivveiioikokiivikoiooookkikkvwveikookkutktktvvwktkkwwkiwiwikkuktkkoiwkkkkotewiikkiukkvwwktkkokkieeiiwiookkiiiiot
&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;Let’s see what we can learn by fitting a recurrent network (of Long Short-Term Memory (LSTM) units).
Since the sequence only exhibits a small alphabet consisting of &lt;tt&gt;{e,i,k,o,t,u,v,w}&lt;/tt&gt;, I’m not going to expend a huge model on it, so I choose an RNN architecture consisting of just one hidden layer with &lt;strong&gt;2 units&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Having trained this small network, let’s observe the output of those two inner units — as points in the plane ${\mathbb R}^2$ — as we pass the sequence through it:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex1_2_2_1_bystate.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;What are the colours? Well, I now need to reveal that the sequence was generated from a 2-state hidden Markov model with states (where the coefficients are shorthand for probabilities of the state outputting each character):&lt;/p&gt;

&lt;p&gt;\[
0.496 {\tt k} + 0.302 {\tt o} + 0.157 {\tt t} + 0.045 {\tt u}
\]&lt;/p&gt;

&lt;p&gt;\[
0.106 {\tt e} + 0.562 {\tt i} + 0.117 {\tt v} + 0.215 {\tt w}
\]&lt;/p&gt;

&lt;p&gt;together with some randomly chosen $2\times 2$ transition matrix for moving between the states. I’ve coloured the plot above by the HMM state. What we see is that this internal structure is effectively discovered by the RNN. (So it gives us some help with question 2 above. I’ll come to question 1 in a moment.)&lt;/p&gt;

&lt;p&gt;This example was very easy because the HMM states are ‘far apart’: they output completely disjoint sets of characters. Let’s look at some other examples. The first does the same as above, but for data generated from a 3-state HMM with closer (overlapping) output distributions. The graph on the right represents the HMM states, with edges representing overlap (actually, closeness of the output distributions using their total variation):&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;
xrrxzzkkzzrxkrzzkkkkzrzoxzkoxrzzzkkzkoznzznznrxxrkkxxrxrrrkrznzxzznzrnnxxxxrrzkkznkkzknznnkzkkokkzzkrrkxknzzoozzzzzzzzzzzoknzzdrroznzzzzznznzznnrxokkxrrozkxrzzkkkrrrxxokkoozkokzzxookozzndzzokzkkxkzxrz
&lt;/tt&gt;&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex2_2_3_1_bystate.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex2_2_3_1_families.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p&gt;Next are two examples using 3 units in the RNN layer, so that now the sequences are represented in ${\mathbb R}^3$. They both use data generated from a 5-state HMM, but with different state configurations:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;
becbcbyooooeceyyjyywccbbbnenennneybooyyywbooobnbyobooobeewyoooywyjwjjywoeeooooooooonbbybbeennnbbccbwyybooennoooooooooooooooooooooooyjwjbbbbbeoobbybeeebyybenegjywyywygenyyybbceennennnnnwjyybbboooecccbb
&lt;/tt&gt;&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex3_3_5_2_3D_bystate.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex3_3_5_2_families.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p&gt;Here, we see that ‘confusion’ between HMM states is well represented in the RNN. The least confused HMM state is state 1, which is uniquely distinguished by outputting only ‘o’, and is coloured blue in the 3-dimensional plot. The most confused state is 4 (red). But remember that the RNN is not trying to distinguish the HMM states — it knows nothing about them — it is simply representing the observed structure of the output sequence. Of course, this structure reflects both the hidden states and their output distributions.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;
kqxvklljguguuuybywfrywrmkvbygglyuuguggggubjljwrwpulljuulrwwrrwugugguuummlppkzlrguupkpkpbytyupkxubuugtbyywhwuvxwrpvupppvybwlwrdpubgyuyxuuuugupxpuxuprwzfbjujljullugukwdzwrtbbbbtbybbbbtuugwfwffuguugbujbb
&lt;/tt&gt;&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex4_3_5_1_3D_bystate.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex4_3_5_1_families.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p&gt;This last example has the most confusion among HMM states, and that is reflected in the 3-dimensional plot. Nevertheless, if we do a dimensional reduction to the plane using $t$-SNE for this example, we see that the separation is in fact still pretty good:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex4_3_5_1_tsne_bystate.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;How well do these RNN models answer problem 1 above? How well do they predict sequence outputs? Let’s focus on the last example.&lt;/p&gt;

&lt;p&gt;First note that the way we &lt;strong&gt;don’t&lt;/strong&gt; want to assess the predictive power of the model is to measure symbol error rate. That way, when we are dealing with inherently high entropy distributions, madness lies. In other words, in our situation each character is generated from a distribution which may be close to uniform, with multiple characters equally likely. Guessing the right one correctly may not tell us very much about the model — what we really need to know is that the model is giving us the right probability distribution.&lt;/p&gt;

&lt;p&gt;Since we have a God’s eye view of the data (it is generated from a Markov chain that we specified!) we know exactly what the right probability distribution is. That is, we know the (HMM) state transition matrix $P$ and the emission matrix $F$ (whose rows are the character distributions conditional on the HMM state). As we observe a sequence generated by the HMM, we can compute the ‘alpha’ vector as we go (which gives the joint probability of a given HMM state with the characters observed so far). Multiplying the alpha (row) vector on the right by the product $PF$ gives the distribution of the next character conditional on the sequence so far observed — exactly what we want.&lt;/p&gt;

&lt;p&gt;The RNN knows nothing about the HMM states, but is also outputting, as a softmax, its estimate of the same conditional distribution at each time step. The correct measure of its performance, therefore, as is how close this softmax is to the HMM-derived distribution.&lt;/p&gt;

&lt;p&gt;Here’s the comparison for the last example above. On the left I’ve plotted, for all possible next characters at all time steps in a test sequence a few thousand long, the predicted RNN (softmax) probability against the actual (HMM) probability. The histogram on the right shows the (mean per time-step) absolute value of the difference:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex4_3_5_1_prob_comparison.png&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;What we see is that the median discrepancy is around 1%. Not bad! Just for good measure, here’s a slightly hard example, with 12 well-mixed HMM states and using a 16-unit RNN (so the coloured plot is a $t$-SNE reduction from ${\mathbb R}^{16}$):&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;
cjydlrmppyygmmmyvprcchcmchauncanpngehshssllshhdolliaicaobdnnnabylroloddpgrbgprpyrpysyxzffefvzvzzewhsabgppyggehlpppyyalolnlddlvebnpbanbnfzebxvvfvbanbnnnoldlnnpnpabwbooupgppubvvfzvvviiaihhspphovvvveshlh
&lt;/tt&gt;&lt;/p&gt;

&lt;figure class=&quot;half &quot;&gt;
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex5_16_12_2_bystate.png&quot; alt=&quot;&quot; /&gt;
    
  
    
      &lt;img src=&quot;/assets/img/2019-11-01/ex5_16_12_1_families.png&quot; alt=&quot;&quot; /&gt;
    
  
  
&lt;/figure&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex5_16_12_2_prob_comparison.png&quot; width=&quot;100%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We get a comparable performance, with median discrepancy around 1%.&lt;/p&gt;

&lt;p&gt;We can (and should!) also ask how these predicted probabilities (by HMM or by RNN) compare with what we actually observe. (This is after all a test we can always apply, not just for toy Markov-generated data.)&lt;/p&gt;

&lt;p&gt;In the plot below I’ve divided the interval $[0,1]$ into 20 bins. For each bin I’ve counted the proportion of character predictions with (HMM or RNN) probability in this range that actually happen. In other words, we’d like to see, if the model is well calibrated, that around 20% of prediction at 0.2 actually happen, and so on. I’ve plotted these proportions (blue for HMM, red for RNN), and the closer the plot to the diagonal, the better calibrated the model:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex5_16_12_1_calibration_no_dropout.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;(Incidentally, being just above the diagonal is actually correct, because the observed proportion has been plotted against the bottom of the corresponding bin range.)&lt;/p&gt;

&lt;p&gt;This shows where the RNN performance is weaker. But up to this point I haven’t said anything about the details of training the RNN. In particular, it’s common to use dropout to prevent overfitting, and the calibration plot above was actually the result of training the RNN without any dropout. Since this calibration is a good measure of the RNN performance, we should compare with an RNN trained with dropout (20% on the dense connections between layers):&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
&lt;img src=&quot;/assets/img/2019-11-01/ex5_16_12_2_calibration_dropout_0pt2.png&quot; width=&quot;70%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;So now the RNN is pretty well spot on.&lt;/p&gt;

&lt;p&gt;What’s needed now is a mathematical analysis to explain the observations above, to tell us how they will scale, how they will extend to high-order dependencies, and how the RNN performance will depend on architecture and training parameters.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html">Modern language models derive their power from big data and big compute – but also, ultimately, from the Unreasonable Effectiveness of Recurrent Neural Networks described by Andrej Karpathy (and many others) a decade or so ago. This post is more low-brow than Karpathy’s — I wanted to explore a little bit how RNNs perform on some carefully controlled toy data: specifically on sequences generated from Markov chains.</summary></entry><entry><title type="html">Mean-squared error versus cross-entropy</title><link href="http://localhost:4000/data_science/crossent/" rel="alternate" type="text/html" title="Mean-squared error versus cross-entropy" /><published>2019-10-01T00:00:00+00:00</published><updated>2019-10-01T00:00:00+00:00</updated><id>http://localhost:4000/data_science/crossent</id><content type="html" xml:base="http://localhost:4000/data_science/crossent/">&lt;p&gt;&lt;a href=&quot;https://billox.shinyapps.io/crossent/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/img/2019-10-01/crossent.png&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This post is about multinomial probability distributions $p = (p_1, \ldots ,p_N)$ where $\sum_i p_i = 1$.&lt;/p&gt;

&lt;p&gt;We often need to compare two such distributions using a ‘distance’ function $d(p,q)$. For example (and the motivation for this blog post was a recent conversation about this case), the error that gets back-propagated when we train a neural network classifier: $p$ is the one-hot vector specifying the class of a training example, and $q$ is the corresponding soft-max output of the network.&lt;/p&gt;

&lt;p&gt;For this, one might use the good old Euclidean metric
\[
d_{\rm Eucl}(p,q) = \left( \sum_i | p_i - q_i |^2 \right)^\frac{1}{2}.
\]&lt;/p&gt;

&lt;p&gt;Alternatively, one can use cross-entropy (not a metric, but motivated from information theory)
\[
d_{\rm CE}(p,q) = \sum_i - p_i \log q_i .
\]&lt;/p&gt;

&lt;p&gt;Discussing these with a colleague recently, I claimed that the Euclidean error is ‘wrong’ because it’s translation-invariant, and this is not appropriate in the space of multinomial distributions, which is a simplex (and therefore bounded). But I thought afterwards it would be a good idea to make a visualisation to demonstrate this, and to understand just how the two metrics compare.&lt;/p&gt;

&lt;p&gt;For $N=3$ this is easy to do because the simplex is a triangle. In the interactive demo (linked to the image above),
select a distribution $p$ by clicking somewhere in the left triangle: the middle and right plots will then show a heat map of ‘distance’ to that point in cross-entropy and in the Euclidean metric respectively.&lt;/p&gt;

&lt;p&gt;What we see is that the Euclidean metric does not know about the geometry of the space of distributions. Cross-entropy, on the other hand, grows to infinity as the second argument $q$ goes to the boundary. So, for example, if $p=(0.9,0.05,0.05)$ and $q=(1,0,0)$, then $p$ and $q$ are very close in the Euclidean metric, but infinitely far apart in cross-entropy.&lt;/p&gt;

&lt;p&gt;(But note that this is not the case if $p$ and $q$ are reversed!! Cross-entropy is not symmetric, and is even linear in the first argument. You can see the effect of swapping direction of the distance measure using the menu below the middle plot.)&lt;/p&gt;

&lt;p&gt;On the other hand, we do see that for distributions that stay away from the boundary — that is, for those with higher entropy — mean squared error is a surprisingly good approximation to cross-entropy, at least for $N=3$.&lt;/p&gt;

&lt;p&gt;Of course, when we’re training neural networks, it’s precisely the low entropy, boundary distributions that matter. It’s the vertex points (one-hot distributions) that we use for training — in the vicinity of which cross-entropy is highly sensitive, while the Euclidean metric is blunt and unobservant.&lt;/p&gt;</content><author><name>Bill Oxbury</name></author><category term="data_science" /><summary type="html"></summary></entry></feed>