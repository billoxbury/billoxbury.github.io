---
title:  "Neural networks in microbes"
date:   2023-11-15
categories: artificial_intelligence
blurb: >- 
    How does nature process information without a nervous system? 
header:
  teaser: "/assets/img/2023-11-15/ecoli.jpg"
---

<figure>
  <img src="/assets/img/2023-11-15/ecoli_size.jpg" width="100%">
  <figcaption>Source: <a href="https://www.uq.edu.au/news/article/2022/01/scientists-uncover-resistance-gene%E2%80%99-deadly-e-coli" target="_blank">University of Queensland</a>
  </figcaption>
</figure>

We tend to think of biological intelligence as arising from animal nervous systems and brains. But consider this. The bacterium <a href="https://en.wikipedia.org/wiki/Escherichia_coli" target ="_blank">Escherichia coli</a>  pictured above is about 0.5 micron across. Thousands could sit in the the cross-section of a human hair. Notably, 0.5 micron is about the same size as a single synapse connecting neurons in the brain. Yet this bacterium can process information, exhibits short-term memory and makes decisions. It has to do so, as does every organism, in order to survive.

<figure>
  <img src="/assets/img/2023-11-15/dendrites_marked.png" width="100%">
  <figcaption>Source: <a href="https://openbooks.lib.msu.edu/neuroscience/chapter/the-neuron/" target="_blank">Foundations of Neuroscience, Michigan State University</a>
  </figcaption>
</figure>

This blog post is inspired by, and heavily draws upon, Dennis Bray's beautiful 2009 book _Wetware_ [1], which describes how this information processing works. The vast majority of organisms do not have nervous systems or brains, and yet they are able to exhibit biological 'intelligence'. The biggest surprise for me in Bray's account is how the molecular information processing that takes place in the cell can be modelled as a <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank">neural network</a> in the same sense as understood in computer science. The units of the network are not nerve cells as we think of for vertebrates (including humans), but are <a href="https://en.wikipedia.org/wiki/Protein" target="_blank">proteins</a>.

Now, although artificial neural networks (ANNs) were originally inspired by the human brain, they are inevitably too coarse a model to represent what really goes on in the brain. In the machine learning community we understand that. We know that we're not really modelling brains, but that ANNs are still a powerful computational device nonetheless - underpinning virtually all of contemporary AI.

What is much less well known is that ANNs as a model are also a way to represent protein-protein interactions (PPIs) in the cell – and probably a much closer model of this than they are of animal brains.

A question it seems ripe to ask is: what lessons might this observation have for Artificial Intelligence?

**TL;DR**

> 1. Clever cells: finding biological intelligence in microbes.
> 2. Protein networks: how proteins implement neural networks in the cell.
> 3. Lessons for AI: Artificial Intelligence has long drawn inspiration from biology - what can we learn from cell intelligence?

**1. Clever cells**

An _E.coli_ bacterium is an autonomous agent (to use the language of AI!) moving in a fluid medium. Its method of locomotion is to rotate its 'tail', made up of a number of flagellae each driven at about 100 Hz by a small molecular motor. The bacterium has two modes of motion: most of the time, all its motors rotate in the same direction, driving it at an approximately constant velocity in one direction. However, the bacterium can decide to reverse the direction of one or more of its motors, in which case it adopts an irregular 'tumble'.

The bacterium also has molecular sense organs, which can detect up to 50 different chemical compounds at concentrations of just 1 part in 10 million. Some of these (e.g. sugars) it wants to steer towards; others (toxins) it wants to avoid. Evolution has equipped _E.coli_ with information processing mechanisms (which we'll come to below) that allow it to detect chemical gradients and adjust its motion to increased concentrations of food and decreased presence of toxins.

Over periods of sustained travel interspersed with tumbling in a viscous medium, the bacterium must regularly update its environmental assessment. In order to detect chemical gradients, it must both estimate concentrations and compare these with previous estimates. For this it needs some form of short-term memory.
It must make decisions based on trade-offs between different (good and bad) chemicals present, and based on its current state of hunger, avoidance of threat etc.

Bacteria like _E.coli_ have mechanisms to process information and convert sensory inputs (plus current internal state) into motor outputs, to achieve survival and reproduction in the competetive struggle with other organisms in the environment. They have clearly been successful in this over most of 4 billion years.

One can assume that their bevaviours are hard-wired by evolution (much like the bots I wrote about in an earlier post <a href="https://billoxbury.github.io/artificial_intelligence/zombie-bots-and-neural-bots/" target="_blank">Zombie bots and neural bots</a>). More sophisticated microbes, on the other hand, also show evidence of _learning_. 

_Protozoa_ are single-celled eukaryotes (cells with a nucleus) and are some orders of magnitude larger than bacteria such as _E.coli_. One of the best known, for example is _Amoeba proteus_, a large predatory protozoan that hunts bacteria and other small organisms. Its mode of transport is different from the swimming of _E.coli_ - it stretches out 'arms' called _pseudopodia_, via cytoplasmic streaming, and changing its whole body shape by flowing into one or more of these pdeudopodia. 

<figure>
  <img src="/assets/img/2023-11-15/amoeba_proteus_size.jpg" width="100%">
  <figcaption>
  Source: <a href="https://en.wikipedia.org/wiki/Amoeba" target="_blank">Wikipedia</a>
  </figcaption>
</figure>

_Amoeba_ feeds by pursuing and ingesting prey which may itself be in motion. To do this, it needs to detect the location and movement of that prey. It needs to adapts its behaviour and mode of locomotion according to type of prey, and to coordinate multiple pseudopodia, both in the pursuit and to surround and engulf its prey. 

Protozoa such as _Amoeba_ respond to chemical gradients, mechanical vibrations, light, temperature, gravity. In other words, they exhibit sensory capability and _attention_. As they respond to their environmental state and
move between distinct states of activity (feeding, travelling, resting, dividing etc), these creatures demonstrate responsiveness to the same range of sensory inputs as multi-celled animals, and the ability to make decisions on appropriate motor outputs. But without any nervous system!

It's interesting to note in passing that _individuality_ of behaviour is observed by researchers - with each bacterium (this is from [1], referring to _E.coli_) "displaying a distinct pattern of swimming"! This shouldn't surprise us as random variation is the basis of evolution by natural selection. We also observe it in much simpler simulated systems too (see the <a href="https://billoxbury.github.io/artificial_intelligence/zombie-bots-and-neural-bots/" target="_blank">earlier blog</a> mentioned above). 

_Associative learning_ - that is, an organism's ability to change its response to a given stimulus in the light of experience - is something we usually associate with brainy animals. However, it turns out there there is a long literature claiming associative learning in various protozoa including _Amoeba_. Many examples can be found in the references [2,3,4]. 

In summary, we can say that in evolutionary terms, biological information processing predated the evolution of nerve cells, nervous systems and brains by about 3 billion years. Not only that, but the capability of biological organisms to _learn_ preceded nervous systems by maybe 1 billion years. In other words, brains and nervous systems are not actually _fundamental_ to biological intelligence. Understanding what is could be really illuminating for those of us thinking about artificial intelligence.

It turns out that the answer still seems to involve neural networks!

**2. Protein networks**

In this section I want to summarise Bray's account in [1] of how information processing works in a cell to achieve the coordination, decision-making and even learning that we've seen above in bacteria and protozoa. The very surprising punchline is that the biochemical mechanisms we describe can be framed as instances of neural networks, in the sense of mathematical <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank">Artificial Neural Networks</a> (ANNs). (And I'm going to assume the reader is familiar with these.)

The key players are the <a href="https://en.wikipedia.org/wiki/Protein" target="_blank">proteins</a>. Each protein molecule is built from a chain of amino acid molecules joined together - drawn from an 'alphabet' of 20 building block amino acids. The 20 amino acids have pairwise attractive and repulsive tendencies, and this causes a characteristic folding pattern of each protein molecule. This folding leads to the protein molecule having a geometry which may have _binding sites_ that can connect to other proteins.

How do proteins interact? There are two fundamental physical mechanisms we need to understand:

The first is _thermal diffusion_, that is, Brownian motion by which molecules are randomly moving around the cell under heat energy, ricocheting off other molecules. The <a href="http://book.bionumbers.org/what-are-the-time-scales-for-diffusion-in-cells/" target="_blank">time scales</a> for this are small: the time for a protein molecule to traverse an _E.coli_ cell is around 10 milliseconds, or 100 times/sec.

When we speak of a protein $P$ in a cell we mean, more precisely, the population of all $P$-molecules in that cell. This may be in the region $10^4$-$10^6$ molecules. So under thermal diffusion, molecules of two proteins $P$ and $Q$ can be expected to meet many thousands of times per second.

The second physical mechanism to mention is what happens when molecules of two proteins $P,Q$ meet. In this event, one or other molecule can attach to binding sites of the other, via affinity of amino acids in the respective geometries. 

In general, stable molecular structures in the cell are formed and maintained by 'strong' bonds (the making and breaking of which requires a significant transfer of energy). Protein interactions, on the other hand, are usually constructed by 'weak' bonds and geometric 'recognition'. The strength of such a bond depends on the geometric goodness of fit.

<figure style="width:75%" class="align-center">
  <img src="/assets/img/2023-11-15/1qha.gif">
  <figcaption>
  Source: <a href="https://proteopedia.org/wiki/index.php/Hexokinase" target="_blank">Protopedia</a>
  </figcaption>
</figure>

What I've described so far, at the most basic level, is how protein-protein interactions (PPIs) work. Just to illustrate the 'social network' of these, the following graph shows 2,234 binary interactions (edges of the graph) among 1,269 proteins (vertices) from the PPI network in _E.coli_:

<figure style="width:100%" class="align-center">
  <img src="/assets/img/2023-11-15/ecoli_ppi_notext.png">
  <figcaption>
  Source: <a href="https://www.nature.com/articles/nbt.2831" target="_blank">Nature</a>, reference [5]
  </figcaption>
</figure>

The next thing to describe is how PPIs - weak binding of proteins through thermal diffusion and geometric recognition - leads to signals which allow propagation of information across a cell.

The key to this is that a protein molecule can exist in more than one (geometric) state. Recalling that the folding geometry of a protein $P$ depends on the net effect of mutual affinities of the amino acids in the constituent chain, it's easy to see that in the presence of a binding protein $Q$ this total effect can change, so that the geometry of $P$ jumps to a different configuration. In this new configuration, new binding properties may appear, switching on or off interactions with other proteins.

The following diagram is taken from [1] directly, and shows a protein which functions as an enzyme (converting $A$ to $A'$) but under regulation by protein $B$. It has the signalling effect of a transistor:

<figure style="width:75%" class="align-center">
  <img src="/assets/img/2023-11-15/transistor.jpg">
  <figcaption>
  Source: reference [1] page 67.
  </figcaption>
</figure>

To quote directly from [1]: 

<p><small>"Two-state proteins are everywhere in a living cell ... they are the building blocks of flagella and cilia ... the molecular motors that harness chemical energy to make a cell divide, a muscle contract, an amoeba crawl ... They are at the heart of the electrical signals produced by nerve cells in our brain and hence underpin all our mental activities."
</small></p>

Some protein switches are held in 'solid state', for increased sensitivity or amplification, or for mechanical reasons. This includes the chemical receptors (signalling across the cell membrane) and the motors (which spin the flagella) in _E.coli_:

<figure style="width:75%" class="align-center">
  <img src="/assets/img/2023-11-15/ecoli_machine.jpg">
  <figcaption>
  Source: reference [1] page 91.
  </figcaption>
</figure>

This diagram illustrates a general principle: any organism, to be independently mobile, must have sensory organs, some internal processing of those signals, and motor outputs that determine physical movement. 

Detection of environmental signals is performed by receptors - protein switches embedded in the external cell membrane as shown above. Cells have hundreds of different kinds of receptors. Switching of a receptor by its target chemical on the outside of the cell activates its molecular function, initiating a chain of PPIs inside the cell. 

(Inevitably, I'm skipping over lots of more complex detail. In particular, this includes efficiencies achieved by regulation of 'third party' background PPIs such as _kinase-phosphatase cycles_. But these all fall within the overall dynamical system of PPIs operating in the cell.)

Let's turn to the internal processing - the decision making that processes the sensory signal and controls the operation of the motor proteins - how does this work?

Bray explicitly recognises that the cell PPIs can be interpreted as a neural network (and has a chapter on this), and illustrate the possible congurations of inputs/outputs with the following diagram:

<figure style="width:75%" class="align-center">
  <img src="/assets/img/2023-11-15/processing.jpg">
  <figcaption>
  Source: reference [1] page 81.
  </figcaption>
</figure>



/**********************************************************/


Protein switches can be controlled by _feedback_ - for example, a process that manufactures an amino acid $A$ runs fast when $A$ is scarce, and slows down as $A$ becomes more abundant. Or they may be controlled by the presence of higher-order regulators in the cell. But at each level there is a primary target and a regulator - and most proteins will have several of each.



p.79 Relevant to part III: there are many kinds of modification to protein structure, which be complex and hierarchical - "they constitute a feature unique to living systems and have no electronic equivalent."
(What's a good algorithmic model?)

Fig 4.3 enzymes as computational elements.

p.81 examples of simple tasks eg oscillators for time keeping etc

"Living organisms, by contrast [with digital computers], seem to be incorrigibly analog."
Then argues that it's less clear cut - with analog aspects of electronic computation and digital aspects in biology such as DNA base sequence, protein switches etc.


(This segues to an argument that NNs provide exactly a model combining digital and analog.)

p.86 relevant to part I: discussion of complex cell reactions for physical motion of cell eg amoeba. Signals have to propagate across the cell for coordinated movement with overall goal eg entrapping prey.

p.92 [In discussion of E.Coli pathways] 
Protein complexes: not all PPIs take place via diffusion - some proteins held in solid state e.g. at sensory protein complexes and at motor 'protein machines'. At sensory end this increases sensitivity and amplification of signals; at motor end enable translation to physical motion.


p 104 remarks about population of protein molecules as not at all homogeneous - more like an irregular slurry with different individuals having quite different loc environments. But still simplify in the PPI network or NN to relating the population as a single functional node 

p.120
"The biochemical pathways regulating glucose in a liver cell make up a sort of neural network."
This is complicated network with multiple inputs at each node (e.g. glucagon, insulin, adrenaline and so on).
Each node is a population of molecules of a particular protein, therefore distinct from other nodes.
Also the network is recurrent (not simply feedforward).

What is the training process? In many cases (e.g. a liver cell) the network connections (i.e. binding strengths, rates of catalysis) are learned through evolution. This is by far the most importnat training signal.
(Cf. 'Zombie bots and neural bots') 
But in some other cases (e.g. cells in the nervous systems and the immune system) there are reinforcement learning processes at work that are only partially understood.

Evolution of optimal pathways for specific biochemical scenarios demonstrated in computer simulations by Dennis Bray and collaborators.

p.125 observes that if biochemical reactions have properties of neural networks, then cells can be expected to react optimally to combinations of stimuli - which is what is observed.

p.126 Gives examples of regulator proteins that behave in typical hidden-unit fashion, taking input from many physiological indicator chemicals and outputting their signal to many targets.

p.127 cites as a benefit of this NN-like system its built-in redundancy: in most cases, if one node of the network is damaged - if the supply of one enzyme or hormone is defective - the system as a whole degrades gracefully rather than catastrophically.



**BLOG 3: Lessons for AI**

Chap 9: 'cells together'
Chemical signals in communities of bacteria. E.g. bioluminescent behaviours, quorum sensing, recognition of foreigners.
These signals can lead to collective behaviour reminiscent of higher organisms. This led to symbiotes (e.g. mitochondria, chloroplasts) and the evolution of multicellular organisms. 

p.170 The biochemical signal pathways in a single cell now extend across the cell membrane and to receptors in other cells.

Some points to note:

- animal nervous system represents a scaling up of molecular NNs. But each neuron contains the same molecular NN capability as the E Coli. So how does this shape info proc of a brain beyond the NN model?

- plants and fungi also process information and like animals have evolutionary root in molecular NNs. This suggests their info proc system might be formally described in NN terms - is that the case?

- if NNs are ubiquitous in biological info proc then they have a universality which suggests NN-based AGI could be very likely.

"Protein-protein interactions are critical steps in many signalling pathways, including those involved in immune cell activation and hormone response."
https://eandt.theiet.org/content/articles/2021/07/engineers-create-protein-circuits-which-respond-in-seconds/


The idea that the biological system for AI to emulate is the human brain feels very 1950s! - which is appropriate since that is when AI research was born. But in the 21st century we can see that this is too naive, and perhaps a better system - or at least more realistic in terms of emulating actual physical processes - is that of protein circuits and cellular information processing.

Main conclusions for AI: ANN-based AGI may soon be a reality processing/deploying multimedia content, writing/deploying code to the cloud BUT

- despite the terminology, it's incorrect to think of ANNs as simulating biological nervous systems
- it would be more accurate to think of ANN-based AGI as akin to a 'synthetic amoeba' operating in human cyber and social networks

For cross-fertilisation of ideas, AI researchers should be more aware of synthetic biology.

**References**

1. Dennis Bray, _Wetware, A Computer in Every Cell_, Yale University Press (2009)
2. Philip Applewhite, <a href="https://books.google.co.uk/books?hl=en&lr=&id=SznlULZ3hi0C&oi=fnd&pg=PA341&dq=learning+in+protozoa&ots=AjJ1310une&sig=ZtGWboHuutf2BXBDqGWg2QJCjhk&redir_esc=y#v=onepage&q=learning%20in%20protozoa&f=false" target="_blank">Learning in protozoa</a>, Biochemistry and physiology of protozoa (1979) 
3. De la Fuente, I.M., Bringas, C., Malaina, I. et al. _Evidence of conditioned behavior in amoebae_,  <a href="https://doi.org/10.1038/s41467-019-11677-w" target="_blank">Nat Commun 10, 3690</a> (2019)
4. Samuel Gershman, Petra Balbi, Randy Gallistel, Jeremy Gunawardena, _Reconsidering the evidence for learning in single cells_ <a href="https://doi.org/10.7554/eLife.61907" target="_blank">eLife 10:e61907</a> (2021)
5. Rajagopala, S., Sikorski, P., Kumar, A. et al., _The binary protein-protein interaction landscape of Escherichia coli._ <a href="https://doi.org/10.1038/nbt.2831" target="_blank">Nat Biotechnol 32, 285–290</a> (2014)

**NOT USED**

<img src="/assets/img/2023-11-15/microbesize.jpg" width="100%">
Source: https://courses.lumenlearning.com/suny-microbiology/chapter/types-of-microorganisms/

<img src="/assets/img/2023-11-15/amoeba.png" width="100%">
Source: https://www.livescience.com/54281-amoeba-definition.html


<img src="/assets/img/2023-11-15/synapse.png" width="100%">
Source: https://en.wikipedia.org/wiki/Chemical_synapse

<img src="/assets/img/2023-11-15/soma.png" width="100%">

<img src="/assets/img/2023-11-15/folding.png" width="100%">
Source: https://www.technologyreview.com/2020/11/30/1012712/deepmind-protein-folding-ai-solved-biology-science-drugs-disease/
